{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "name": "Bert Model using pytorch (Summer).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf8wc3kOBh4A",
        "outputId": "7c7b2d2b-214d-4ec7-a21a-f628913e36fc"
      },
      "source": [
        "!pip install datasets==1.0.1\n",
        "!pip install transformers==3.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets==1.0.1 in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.1) (3.0.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.1) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.1) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.1) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.1) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.1) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.1) (1.1.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.1) (0.3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.1) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.1) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.0.1) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.0.1) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.0.1) (1.15.0)\n",
            "Requirement already satisfied: transformers==3.1.0 in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (0.8.1rc2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (0.1.95)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (1.19.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEYvlndRBCXA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3U6EuZ3BCXM"
      },
      "source": [
        "train = open(\"//train.txt\", \"r\").read()\n",
        "train_sep = train.rsplit(\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMVBMn4vBCXM"
      },
      "source": [
        "test = open(\"//test.txt\", \"r\").read()\n",
        "test_sep = test.rsplit(\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnHpQxykBCXN"
      },
      "source": [
        "train_set = pd.DataFrame(train_sep)\n",
        "train_res = pd.DataFrame(train_set.values.reshape(584,6))\n",
        "train_dataset, val_dataset = train_test_split(train_res.drop(columns=[5]), test_size=0.2)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "val_dataset = val_dataset.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tj7ONsSBCXN"
      },
      "source": [
        "test_set = pd.DataFrame(test_sep)\n",
        "test_res = pd.DataFrame(test_set.values.reshape(174,6))\n",
        "test_dataset = test_res.drop(columns=[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR8WFHh8BCXO"
      },
      "source": [
        "#transforming the dataset\n",
        "def transform_label(label):\n",
        "    if label == \"H\":\n",
        "        return 0\n",
        "    elif label == \"M\":\n",
        "        return 1\n",
        "    else:\n",
        "        raise\n",
        "train_dataset[4] = train_dataset[4].apply(transform_label)\n",
        "val_dataset[4] = val_dataset[4].apply(transform_label)\n",
        "test_dataset[4] = test_dataset[4].apply(transform_label)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "D3r7TR67BCXO",
        "outputId": "cec4c848-786c-49c9-fa59-a11c9f934d4e"
      },
      "source": [
        "val_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>布 斯 瑞 迪 和数 以千计 的 其他 灾民 一样 , 因为 海啸 而 失去 身份证 和 其...</td>\n",
              "      <td>busriadi , like thousands of other refugees , ...</td>\n",
              "      <td>like thousands of other victims , busriadi los...</td>\n",
              "      <td>0.6781</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>连续 六 年 减少 援外 预算 的 日本 也 迅速 以 行动 粉碎 了 国力 日 衰 的 说...</td>\n",
              "      <td>japan , which has been reducing its foreign ai...</td>\n",
              "      <td>japan , which has cut its foreign aid budget i...</td>\n",
              "      <td>0.6304</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>外务 省 发言人 说 , 小 泉 所 说 的 五 亿 美元 也 包括 这 三 千万 美元 .</td>\n",
              "      <td>a foreign ministry spokesman said that the amo...</td>\n",
              "      <td>a spokesman for the foreign ministry said that...</td>\n",
              "      <td>0.4194</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>联合国 秘书长 安南 委托 以前 哈佛 经济学家 沙 克 斯 为首 的 开发 专家 编撰 这...</td>\n",
              "      <td>un secretary general annan has commissioned fo...</td>\n",
              "      <td>un secretary general annan commissioned develo...</td>\n",
              "      <td>0.7114</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>成千上万 的 尤 申 科 支持 者 已 在 首都 基辅 聚集 两 周 , 他们 包围 政府 ...</td>\n",
              "      <td>tens of thousands of yushchenko's supporters h...</td>\n",
              "      <td>thousands of supporters in the capital gathere...</td>\n",
              "      <td>0.4522</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>数 千 信徒 赶 往 伯 利 恒 参加 平安 夜 弥 撒</td>\n",
              "      <td>thousands of worshippers head to bethlehem for...</td>\n",
              "      <td>thousands of believers to bethlehem to partici...</td>\n",
              "      <td>0.4167</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>南韩 大使馆 则 说 , 李 海 瓒 将 在 斯里兰卡 总理 陪同 下 , 访 视 西部 海...</td>\n",
              "      <td>the south korean embassy said in a statement t...</td>\n",
              "      <td>south korean embassy , said that li hai , refl...</td>\n",
              "      <td>0.5828</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>ZEW 指数 十一月 由 前 月 的 三十 一点 三 , 大 幅 跌 至 十三点 九 .</td>\n",
              "      <td>the zew index fell sharply to 13.9 in november...</td>\n",
              "      <td>the zew index plummeted to 13.9 in november fr...</td>\n",
              "      <td>0.8667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>欧盟 在 与 中国 总理 温 家宝 举行 峰 会 后 发布 的 联合声明 中 说 : \" 欧...</td>\n",
              "      <td>\" the eu side has confirmed its political will...</td>\n",
              "      <td>in a joint declaration released after the summ...</td>\n",
              "      <td>0.8611</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>欧 元 区 本 周 经济 指标 将 显示 欧洲 经济 持续 疲 弱</td>\n",
              "      <td>this week's eurozone economic indicators to sh...</td>\n",
              "      <td>euro zone economic targets this week will demo...</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>117 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     0  ...  4\n",
              "0    布 斯 瑞 迪 和数 以千计 的 其他 灾民 一样 , 因为 海啸 而 失去 身份证 和 其...  ...  0\n",
              "1    连续 六 年 减少 援外 预算 的 日本 也 迅速 以 行动 粉碎 了 国力 日 衰 的 说...  ...  0\n",
              "2       外务 省 发言人 说 , 小 泉 所 说 的 五 亿 美元 也 包括 这 三 千万 美元 .  ...  0\n",
              "3    联合国 秘书长 安南 委托 以前 哈佛 经济学家 沙 克 斯 为首 的 开发 专家 编撰 这...  ...  0\n",
              "4    成千上万 的 尤 申 科 支持 者 已 在 首都 基辅 聚集 两 周 , 他们 包围 政府 ...  ...  1\n",
              "..                                                 ...  ... ..\n",
              "112                       数 千 信徒 赶 往 伯 利 恒 参加 平安 夜 弥 撒  ...  1\n",
              "113  南韩 大使馆 则 说 , 李 海 瓒 将 在 斯里兰卡 总理 陪同 下 , 访 视 西部 海...  ...  1\n",
              "114       ZEW 指数 十一月 由 前 月 的 三十 一点 三 , 大 幅 跌 至 十三点 九 .  ...  0\n",
              "115  欧盟 在 与 中国 总理 温 家宝 举行 峰 会 后 发布 的 联合声明 中 说 : \" 欧...  ...  0\n",
              "116                  欧 元 区 本 周 经济 指标 将 显示 欧洲 经济 持续 疲 弱  ...  1\n",
              "\n",
              "[117 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS9-yNNGBCXP"
      },
      "source": [
        "class TranslationDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, token_length, EtoEmodel='albert-base-v2'):\n",
        "\n",
        "        self.data = data\n",
        "        self.tokenizer1 = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "        self.tokenizer2 = AutoTokenizer.from_pretrained(EtoEmodel)\n",
        "        self.tokenlength = token_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sentence1 = str(self.data.loc[index, 0])\n",
        "        sentence2 = str(self.data.loc[index, 1])\n",
        "        sentence3 = str(self.data.loc[index, 2])\n",
        "\n",
        "        encoded_pair1 = self.tokenizer1(sentence1, sentence2, \n",
        "                                      padding='max_length',\n",
        "                                      truncation=True,\n",
        "                                      max_length=self.tokenlength,  \n",
        "                                      return_tensors='pt')\n",
        "        \n",
        "        encoded_pair2 = self.tokenizer2(sentence2, sentence3, \n",
        "                                      padding='max_length',\n",
        "                                      truncation=True,\n",
        "                                      max_length=self.tokenlength,  \n",
        "                                      return_tensors='pt')\n",
        "        \n",
        "        encoded_pair3 = self.tokenizer1(sentence1, sentence3, \n",
        "                                      padding='max_length',\n",
        "                                      truncation=True,\n",
        "                                      max_length=self.tokenlength,  \n",
        "                                      return_tensors='pt')\n",
        "        \n",
        "        token_ids1 = encoded_pair1['input_ids']\n",
        "        attn_masks1 = encoded_pair1['attention_mask']\n",
        "        token_type_ids1 = encoded_pair1['token_type_ids']\n",
        "        token_ids2 = encoded_pair2['input_ids']\n",
        "        attn_masks2 = encoded_pair2['attention_mask']\n",
        "        token_type_ids2 = encoded_pair2['token_type_ids']\n",
        "        token_ids3 = encoded_pair3['input_ids']\n",
        "        attn_masks3 = encoded_pair3['attention_mask']\n",
        "        token_type_ids3 = encoded_pair3['token_type_ids']\n",
        "        bleu_score = self.data.loc[index, 3]\n",
        "        label = self.data.loc[index, 4]\n",
        "        return token_ids1, attn_masks1, token_type_ids1, token_ids2, attn_masks2, token_type_ids2, token_ids3, attn_masks3, token_type_ids3, torch.Tensor([float(bleu_score)]), torch.Tensor([float(label)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQhBNVYpBCXQ",
        "outputId": "6fb74cd5-5998-490e-af27-f0dadb6ac296"
      },
      "source": [
        "class MachineHumanTranslationClassifier(nn.Module):\n",
        "    def __init__(self, EtoEmodel=\"albert-base-v2\", EtoEhs=768, freeze_bert=False):\n",
        "        super(MachineHumanTranslationClassifier, self).__init__()\n",
        "        \n",
        "        self.bert_layer1 = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "        self.bert_layer2 = AutoModel.from_pretrained(EtoEmodel)\n",
        "        self.bert_layer3 = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "        if freeze_bert:\n",
        "            for p in self.bert_layer1.parameters():\n",
        "                p.requires_grad = False\n",
        "            for p in self.bert_layer2.parameters():\n",
        "                p.requires_grad = False\n",
        "            for p in self.bert_layer3.parameters():\n",
        "                p.requires_grad = False\n",
        "        self.hidden_layer1 = nn.Linear(768, 1)\n",
        "        self.hidden_layer2 = nn.Linear(EtoEhs, 1)\n",
        "        self.hidden_layer3 = nn.Linear(768, 1)\n",
        "        #Final layer converges the results of the 3 hidden layers, and merges it into one out put with the bleu score\n",
        "        self.final_layer = nn.Linear(4, 1)\n",
        "        self.dropout_reg = nn.Dropout(p=0.1)\n",
        "        self.hidden_act = torch.nn.ReLU()\n",
        "        self.final_activation = torch.nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "    @autocast()\n",
        "    def forward(self, token_ids1, attn_masks1, token_type_ids1, token_ids2, attn_masks2, token_type_ids2, token_ids3, attn_masks3, token_type_ids3, bleu_score):\n",
        "        _, pooler_output1 = self.bert_layer1(token_ids1, attn_masks1, token_type_ids1, return_dict=False)\n",
        "        _, pooler_output2 = self.bert_layer2(token_ids2, attn_masks2, token_type_ids2, return_dict=False)\n",
        "        _, pooler_output3 = self.bert_layer3(token_ids3, attn_masks3, token_type_ids3, return_dict=False)\n",
        "        res1 = self.hidden_layer1(self.dropout_reg(pooler_output1))\n",
        "        res2 = self.hidden_layer2(self.dropout_reg(pooler_output2))\n",
        "        res3 = self.hidden_layer3(self.dropout_reg(pooler_output3))\n",
        "        res_fin = torch.cat([res1, res2, res3, torch.Tensor([[bleu_score]])])\n",
        "        final_act = self.hidden_act(torch.transpose(res_fin, 0, 1))\n",
        "        final_out = self.final_layer(final_act)\n",
        "        \n",
        "        return self.final_activation(final_out)\n",
        "        \n",
        "             \n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/autocast_mode.py:118: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUumJ-vJBCXQ"
      },
      "source": [
        "\n",
        "def evaluate_loss(classifier, criterion, dataloader):\n",
        "    classifier.eval()\n",
        "\n",
        "    mean_loss = 0\n",
        "    count = 0\n",
        "    dataset_size = len(dataloader)\n",
        "    with torch.no_grad():\n",
        "        for i in range(dataset_size):\n",
        "            token_ids1, attn_masks1, token_type_ids1, token_ids2, attn_masks2, token_type_ids2, token_ids3, attn_masks3, token_type_ids3, bleu_score, label = dataloader[i]\n",
        "            result = classifier(token_ids1, attn_masks1, token_type_ids1, token_ids2, attn_masks2, token_type_ids2, token_ids3, attn_masks3, token_type_ids3, bleu_score)\n",
        "            mean_loss += criterion(result.squeeze(-1), label.float()).item()\n",
        "            count += 1\n",
        "\n",
        "    return mean_loss / count\n",
        "\n",
        "def accuracy_score(classifier, criterion, dataloader):\n",
        "    classifier.eval()\n",
        "\n",
        "    total_correct = 0\n",
        "    count = 0\n",
        "    dataset_size = len(dataloader)\n",
        "    with torch.no_grad():\n",
        "        for i in range(dataset_size):\n",
        "            token_ids1, attn_masks1, token_type_ids1, token_ids2, attn_masks2, token_type_ids2, token_ids3, attn_masks3, token_type_ids3, bleu_score, label = dataloader[i]\n",
        "            result = classifier(token_ids1, attn_masks1, token_type_ids1, token_ids2, attn_masks2, token_type_ids2, token_ids3, attn_masks3, token_type_ids3, bleu_score)\n",
        "            if result.item() >= 0.5:\n",
        "                pred = 1\n",
        "            else:\n",
        "                pred = 0\n",
        "            if pred == int(label.item()):\n",
        "                total_correct += 1\n",
        "            count += 1\n",
        "    return total_correct / count\n",
        "\n",
        "def evaluate_loss_acc(classifier, criterion, dataloader):\n",
        "    classifier.eval()\n",
        "\n",
        "    mean_loss = 0\n",
        "    total_correct = 0\n",
        "    count = 0\n",
        "    dataset_size = len(dataloader)\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(dataset_size)):\n",
        "            token_ids1, attn_masks1, token_type_ids1, token_ids2, attn_masks2, token_type_ids2, token_ids3, attn_masks3, token_type_ids3, bleu_score, label = dataloader[i]\n",
        "            result = classifier(token_ids1, attn_masks1, token_type_ids1, token_ids2, attn_masks2, token_type_ids2, token_ids3, attn_masks3, token_type_ids3, bleu_score)\n",
        "            mean_loss += criterion(result.squeeze(-1), label.float()).item()\n",
        "            if result.item() >= 0.5:\n",
        "                pred = 1\n",
        "            else:\n",
        "                pred = 0\n",
        "            if pred == int(label.item()):\n",
        "                total_correct += 1\n",
        "            count += 1\n",
        "    return mean_loss / count, total_correct / count\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOT9UDr0BCXR"
      },
      "source": [
        "def train_bert_clf(model, opti, lr, lr_scheduler, train_loader, val_loader, epochs, mini_batch):\n",
        "    total_iter = len(train_loader)\n",
        "    check = total_iter // 5  # print the training loss 5 times per epoch\n",
        "    loss_fn = nn.BCELoss()\n",
        "    check_loss = 0.0\n",
        "    dataset_size = len(train_loader)\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        for i in tqdm(range(dataset_size)):\n",
        "            token_ids1, attn_masks1, token_type_ids1, token_ids2, attn_masks2, token_type_ids2, token_ids3, attn_masks3, token_type_ids3, bleu_score, label = train_loader[i]\n",
        "            with autocast():\n",
        "                result = model(token_ids1, attn_masks1, token_type_ids1, token_ids2, attn_masks2, token_type_ids2, token_ids3, attn_masks3, token_type_ids3, bleu_score)\n",
        "                loss = loss_fn(result.squeeze(-1), label.float())\n",
        "                loss = loss / mini_batch\n",
        "                loss.backward()\n",
        "                \n",
        "            if (i + 1) % mini_batch == 0:\n",
        "                opti.step()\n",
        "                lr_scheduler.step()\n",
        "                opti.zero_grad()\n",
        "                \n",
        "            check_loss += loss.item()\n",
        "            \n",
        "            if (i+1) % check == 0:\n",
        "                print(\"Iteration {} / {} of epoch {} loss is: {}\"\n",
        "                      .format(i+1, total_iter, ep + 1, (check_loss / check)))\n",
        "                check_loss = 0.0\n",
        "        \n",
        "    train_loss, train_acc = evaluate_loss_acc(model, loss_fn, train_loader)\n",
        "    val_loss, val_acc = evaluate_loss_acc(model, loss_fn, val_loader)\n",
        "    print(\"Train Loss: {}\".format(train_loss))\n",
        "    print(\"Train Accuracy: {}\".format(train_acc))\n",
        "    print(\"Validation Loss: {}\".format(val_loss))\n",
        "    print(\"Validation Accuracy: {}\".format(val_acc))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "    return train_loss, train_acc, val_loss, val_acc, model\n",
        "        \n",
        "        \n",
        "            \n",
        "            \n",
        "            \n",
        "                \n",
        "                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPqByYGzBCXS"
      },
      "source": [
        "bert_model = \"albert-base-v2\"  \n",
        "freeze_bert = False\n",
        "token_length = 128\n",
        "mini_batch = 2 \n",
        "lr = 2e-5\n",
        "epochs = 4\n",
        "loss_fn = nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRvF9BToBCXS"
      },
      "source": [
        "train_loader = TranslationDataset(train_dataset, token_length, bert_model)\n",
        "val_loader = TranslationDataset(val_dataset, token_length, bert_model)\n",
        "test_dataset = TranslationDataset(test_dataset, token_length, bert_model)\n",
        "model = MachineHumanTranslationClassifier()\n",
        "opti = AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
        "total_steps = (len(train_loader) // mini_batch) * epochs \n",
        "lr_scheduler = get_linear_schedule_with_warmup(optimizer=opti, num_warmup_steps=0, num_training_steps=total_steps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e-S_A7FBCXS",
        "outputId": "0c9815cc-edad-42be-9787-0d84e9afa008"
      },
      "source": [
        "train_losses, val_losses, train_accuracies, val_accuracies, model = train_bert_clf(model, opti, lr, lr_scheduler, train_loader, val_loader, epochs, mini_batch)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/467 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/autocast_mode.py:118: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n",
            " 20%|█▉        | 93/467 [09:27<36:06,  5.79s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 93 / 467 of epoch 1 loss is: 0.31444803489151824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 186/467 [18:56<30:10,  6.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 186 / 467 of epoch 1 loss is: 0.31135692471458065\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 279/467 [28:17<17:58,  5.74s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 279 / 467 of epoch 1 loss is: 0.2897777224900902\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 372/467 [37:39<09:56,  6.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 372 / 467 of epoch 1 loss is: 0.27636370615613076\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 465/467 [46:54<00:11,  5.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 465 / 467 of epoch 1 loss is: 0.2648846418146164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 467/467 [47:06<00:00,  6.05s/it]\n",
            " 20%|█▉        | 93/467 [09:11<35:31,  5.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 93 / 467 of epoch 2 loss is: 0.21232041396120543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 186/467 [18:33<29:00,  6.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 186 / 467 of epoch 2 loss is: 0.2234598145850243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 279/467 [27:52<18:06,  5.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 279 / 467 of epoch 2 loss is: 0.23067563571917113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 372/467 [37:13<09:58,  6.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 372 / 467 of epoch 2 loss is: 0.24865091011248608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 465/467 [46:36<00:11,  5.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 465 / 467 of epoch 2 loss is: 0.21095804337372062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 467/467 [46:48<00:00,  6.01s/it]\n",
            " 20%|█▉        | 93/467 [09:17<35:56,  5.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 93 / 467 of epoch 3 loss is: 0.18188822021087012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 186/467 [18:45<30:15,  6.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 186 / 467 of epoch 3 loss is: 0.1945588959641354\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 279/467 [28:53<19:54,  6.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 279 / 467 of epoch 3 loss is: 0.20824040985235603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 372/467 [39:28<11:25,  7.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 372 / 467 of epoch 3 loss is: 0.18624564494577148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 465/467 [50:25<00:13,  6.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 465 / 467 of epoch 3 loss is: 0.1825745945135432\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 467/467 [50:40<00:00,  6.51s/it]\n",
            " 20%|█▉        | 93/467 [11:51<46:03,  7.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 93 / 467 of epoch 4 loss is: 0.13970046949082165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 186/467 [23:53<38:19,  8.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 186 / 467 of epoch 4 loss is: 0.17743328197668956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 279/467 [35:52<23:28,  7.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 279 / 467 of epoch 4 loss is: 0.1806336275992855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 372/467 [48:13<12:55,  8.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 372 / 467 of epoch 4 loss is: 0.16907327243637654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 465/467 [59:59<00:14,  7.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 465 / 467 of epoch 4 loss is: 0.18393851980887432\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 467/467 [1:00:14<00:00,  7.74s/it]\n",
            "100%|██████████| 467/467 [12:50<00:00,  1.65s/it]\n",
            "100%|██████████| 117/117 [03:15<00:00,  1.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: 0.320592951492209\n",
            "Train Accuracy: 0.9914346895074947\n",
            "Validation Loss: 0.4257999953742211\n",
            "Validation Accuracy: 0.9487179487179487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QPunOLLGDT5",
        "outputId": "d22383cd-f3b5-4627-ae59-95203b050461"
      },
      "source": [
        "train_loss, train_acc, val_loss, val_acc = train_losses, val_losses, train_accuracies, val_accuracies\n",
        "train_loss, train_acc, val_loss, val_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.320592951492209, 0.9914346895074947, 0.4257999953742211, 0.9487179487179487)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7-e-L94BCXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e59e0080-f4a4-4ef0-e595-6f468f6143aa"
      },
      "source": [
        "evaluate_loss_acc(model, loss_fn, test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 174/174 [04:53<00:00,  1.69s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4880423700201443, 0.867816091954023)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vLkVptLBCXT"
      },
      "source": [
        "optimal_model = model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRG3V0eEBCXT"
      },
      "source": [
        "def evaluateF1score(classifier, dataloader):\n",
        "    classifier.eval()\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    true_negatives = 0\n",
        "    false_negatives = 0\n",
        "    total_correct = 0\n",
        "    count = 0\n",
        "    dataset_size = len(dataloader)\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(dataset_size)):\n",
        "            token_ids1, attn_masks1, token_type_ids1, token_ids2, attn_masks2, token_type_ids2, token_ids3, attn_masks3, token_type_ids3, bleu_score, label = dataloader[i]\n",
        "            result = classifier(token_ids1, attn_masks1, token_type_ids1, token_ids2, attn_masks2, token_type_ids2, token_ids3, attn_masks3, token_type_ids3, bleu_score)\n",
        "            if result.item() >= 0.5:\n",
        "                pred = 1\n",
        "            else:\n",
        "                pred = 0\n",
        "            if pred == int(label.item()):\n",
        "                if pred == 1:\n",
        "                    true_positives += 1\n",
        "                else:\n",
        "                    true_negatives += 1\n",
        "            else:\n",
        "                if pred == 1:\n",
        "                    false_positives += 1\n",
        "                else:\n",
        "                    false_negatives += 1\n",
        "    precision = true_positives / (true_positives + false_positives)\n",
        "    recall = true_positives / (true_positives + false_negatives)\n",
        "    F1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return F1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJTkcDw4qFJe",
        "outputId": "6b7d16c8-885d-4d4c-aa42-8fefd388e020"
      },
      "source": [
        "train_f1 = evaluateF1score(optimal_model, train_loader)\n",
        "val_f1 = evaluateF1score(optimal_model, val_loader)\n",
        "test_f1 = evaluateF1score(optimal_model, test_dataset)\n",
        "print(\"Train F1 score: {}\".format(train_f1))\n",
        "print(\"Validation F1 score: {}\".format(val_f1))\n",
        "print(\"Test F1 score: {}\".format(test_f1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/467 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/467 [00:01<13:38,  1.76s/it]\u001b[A\n",
            "  0%|          | 2/467 [00:03<13:31,  1.75s/it]\u001b[A\n",
            "  1%|          | 3/467 [00:05<13:29,  1.74s/it]\u001b[A\n",
            "  1%|          | 4/467 [00:06<13:25,  1.74s/it]\u001b[A\n",
            "  1%|          | 5/467 [00:08<13:21,  1.74s/it]\u001b[A\n",
            "  1%|▏         | 6/467 [00:10<13:17,  1.73s/it]\u001b[A\n",
            "  1%|▏         | 7/467 [00:12<13:14,  1.73s/it]\u001b[A\n",
            "  2%|▏         | 8/467 [00:13<13:08,  1.72s/it]\u001b[A\n",
            "  2%|▏         | 9/467 [00:15<13:11,  1.73s/it]\u001b[A\n",
            "  2%|▏         | 10/467 [00:17<13:07,  1.72s/it]\u001b[A\n",
            "  2%|▏         | 11/467 [00:19<13:06,  1.72s/it]\u001b[A\n",
            "  3%|▎         | 12/467 [00:20<13:04,  1.72s/it]\u001b[A\n",
            "  3%|▎         | 13/467 [00:22<13:02,  1.72s/it]\u001b[A\n",
            "  3%|▎         | 14/467 [00:24<13:02,  1.73s/it]\u001b[A\n",
            "  3%|▎         | 15/467 [00:25<12:59,  1.72s/it]\u001b[A\n",
            "  3%|▎         | 16/467 [00:27<12:56,  1.72s/it]\u001b[A\n",
            "  4%|▎         | 17/467 [00:29<12:51,  1.71s/it]\u001b[A\n",
            "  4%|▍         | 18/467 [00:31<12:48,  1.71s/it]\u001b[A\n",
            "  4%|▍         | 19/467 [00:32<12:49,  1.72s/it]\u001b[A\n",
            "  4%|▍         | 20/467 [00:34<12:49,  1.72s/it]\u001b[A\n",
            "  4%|▍         | 21/467 [00:36<12:46,  1.72s/it]\u001b[A\n",
            "  5%|▍         | 22/467 [00:37<12:42,  1.71s/it]\u001b[A\n",
            "  5%|▍         | 23/467 [00:39<12:41,  1.71s/it]\u001b[A\n",
            "  5%|▌         | 24/467 [00:41<12:44,  1.73s/it]\u001b[A\n",
            "  5%|▌         | 25/467 [00:43<12:40,  1.72s/it]\u001b[A\n",
            "  6%|▌         | 26/467 [00:44<12:38,  1.72s/it]\u001b[A\n",
            "  6%|▌         | 27/467 [00:46<12:33,  1.71s/it]\u001b[A\n",
            "  6%|▌         | 28/467 [00:48<12:30,  1.71s/it]\u001b[A\n",
            "  6%|▌         | 29/467 [00:49<12:27,  1.71s/it]\u001b[A\n",
            "  6%|▋         | 30/467 [00:51<12:25,  1.71s/it]\u001b[A\n",
            "  7%|▋         | 31/467 [00:53<12:24,  1.71s/it]\u001b[A\n",
            "  7%|▋         | 32/467 [00:55<12:25,  1.71s/it]\u001b[A\n",
            "  7%|▋         | 33/467 [00:56<12:26,  1.72s/it]\u001b[A\n",
            "  7%|▋         | 34/467 [00:58<12:22,  1.71s/it]\u001b[A\n",
            "  7%|▋         | 35/467 [01:00<12:18,  1.71s/it]\u001b[A\n",
            "  8%|▊         | 36/467 [01:01<12:16,  1.71s/it]\u001b[A\n",
            "  8%|▊         | 37/467 [01:03<12:15,  1.71s/it]\u001b[A\n",
            "  8%|▊         | 38/467 [01:05<12:13,  1.71s/it]\u001b[A\n",
            "  8%|▊         | 39/467 [01:07<12:13,  1.71s/it]\u001b[A\n",
            "  9%|▊         | 40/467 [01:08<12:09,  1.71s/it]\u001b[A\n",
            "  9%|▉         | 41/467 [01:10<12:05,  1.70s/it]\u001b[A\n",
            "  9%|▉         | 42/467 [01:12<12:00,  1.70s/it]\u001b[A\n",
            "  9%|▉         | 43/467 [01:13<12:00,  1.70s/it]\u001b[A\n",
            "  9%|▉         | 44/467 [01:15<12:00,  1.70s/it]\u001b[A\n",
            " 10%|▉         | 45/467 [01:17<11:58,  1.70s/it]\u001b[A\n",
            " 10%|▉         | 46/467 [01:18<11:56,  1.70s/it]\u001b[A\n",
            " 10%|█         | 47/467 [01:20<11:56,  1.71s/it]\u001b[A\n",
            " 10%|█         | 48/467 [01:22<11:55,  1.71s/it]\u001b[A\n",
            " 10%|█         | 49/467 [01:24<11:54,  1.71s/it]\u001b[A\n",
            " 11%|█         | 50/467 [01:25<11:54,  1.71s/it]\u001b[A\n",
            " 11%|█         | 51/467 [01:27<11:52,  1.71s/it]\u001b[A\n",
            " 11%|█         | 52/467 [01:29<11:51,  1.72s/it]\u001b[A\n",
            " 11%|█▏        | 53/467 [01:30<11:46,  1.71s/it]\u001b[A\n",
            " 12%|█▏        | 54/467 [01:32<11:47,  1.71s/it]\u001b[A\n",
            " 12%|█▏        | 55/467 [01:34<11:43,  1.71s/it]\u001b[A\n",
            " 12%|█▏        | 56/467 [01:36<11:41,  1.71s/it]\u001b[A\n",
            " 12%|█▏        | 57/467 [01:37<11:39,  1.71s/it]\u001b[A\n",
            " 12%|█▏        | 58/467 [01:39<11:40,  1.71s/it]\u001b[A\n",
            " 13%|█▎        | 59/467 [01:41<11:37,  1.71s/it]\u001b[A\n",
            " 13%|█▎        | 60/467 [01:42<11:35,  1.71s/it]\u001b[A\n",
            " 13%|█▎        | 61/467 [01:44<11:36,  1.72s/it]\u001b[A\n",
            " 13%|█▎        | 62/467 [01:46<11:35,  1.72s/it]\u001b[A\n",
            " 13%|█▎        | 63/467 [01:48<11:36,  1.72s/it]\u001b[A\n",
            " 14%|█▎        | 64/467 [01:49<11:34,  1.72s/it]\u001b[A\n",
            " 14%|█▍        | 65/467 [01:51<11:30,  1.72s/it]\u001b[A\n",
            " 14%|█▍        | 66/467 [01:53<11:26,  1.71s/it]\u001b[A\n",
            " 14%|█▍        | 67/467 [01:54<11:25,  1.71s/it]\u001b[A\n",
            " 15%|█▍        | 68/467 [01:56<11:23,  1.71s/it]\u001b[A\n",
            " 15%|█▍        | 69/467 [01:58<11:19,  1.71s/it]\u001b[A\n",
            " 15%|█▍        | 70/467 [02:00<11:18,  1.71s/it]\u001b[A\n",
            " 15%|█▌        | 71/467 [02:01<11:17,  1.71s/it]\u001b[A\n",
            " 15%|█▌        | 72/467 [02:03<11:16,  1.71s/it]\u001b[A\n",
            " 16%|█▌        | 73/467 [02:05<11:15,  1.71s/it]\u001b[A\n",
            " 16%|█▌        | 74/467 [02:06<11:15,  1.72s/it]\u001b[A\n",
            " 16%|█▌        | 75/467 [02:08<11:13,  1.72s/it]\u001b[A\n",
            " 16%|█▋        | 76/467 [02:10<11:17,  1.73s/it]\u001b[A\n",
            " 16%|█▋        | 77/467 [02:12<11:12,  1.73s/it]\u001b[A\n",
            " 17%|█▋        | 78/467 [02:13<11:09,  1.72s/it]\u001b[A\n",
            " 17%|█▋        | 79/467 [02:15<11:06,  1.72s/it]\u001b[A\n",
            " 17%|█▋        | 80/467 [02:17<11:03,  1.72s/it]\u001b[A\n",
            " 17%|█▋        | 81/467 [02:18<11:00,  1.71s/it]\u001b[A\n",
            " 18%|█▊        | 82/467 [02:20<10:56,  1.71s/it]\u001b[A\n",
            " 18%|█▊        | 83/467 [02:22<10:54,  1.71s/it]\u001b[A\n",
            " 18%|█▊        | 84/467 [02:24<10:52,  1.70s/it]\u001b[A\n",
            " 18%|█▊        | 85/467 [02:25<10:56,  1.72s/it]\u001b[A\n",
            " 18%|█▊        | 86/467 [02:27<10:51,  1.71s/it]\u001b[A\n",
            " 19%|█▊        | 87/467 [02:29<10:48,  1.71s/it]\u001b[A\n",
            " 19%|█▉        | 88/467 [02:30<10:45,  1.70s/it]\u001b[A\n",
            " 19%|█▉        | 89/467 [02:32<10:45,  1.71s/it]\u001b[A\n",
            " 19%|█▉        | 90/467 [02:34<10:45,  1.71s/it]\u001b[A\n",
            " 19%|█▉        | 91/467 [02:36<10:46,  1.72s/it]\u001b[A\n",
            " 20%|█▉        | 92/467 [02:37<10:48,  1.73s/it]\u001b[A\n",
            " 20%|█▉        | 93/467 [02:39<10:42,  1.72s/it]\u001b[A\n",
            " 20%|██        | 94/467 [02:41<10:39,  1.71s/it]\u001b[A\n",
            " 20%|██        | 95/467 [02:42<10:38,  1.72s/it]\u001b[A\n",
            " 21%|██        | 96/467 [02:44<10:36,  1.72s/it]\u001b[A\n",
            " 21%|██        | 97/467 [02:46<10:32,  1.71s/it]\u001b[A\n",
            " 21%|██        | 98/467 [02:48<10:34,  1.72s/it]\u001b[A\n",
            " 21%|██        | 99/467 [02:49<10:30,  1.71s/it]\u001b[A\n",
            " 21%|██▏       | 100/467 [02:51<10:26,  1.71s/it]\u001b[A\n",
            " 22%|██▏       | 101/467 [02:53<10:24,  1.71s/it]\u001b[A\n",
            " 22%|██▏       | 102/467 [02:54<10:27,  1.72s/it]\u001b[A\n",
            " 22%|██▏       | 103/467 [02:56<10:26,  1.72s/it]\u001b[A\n",
            " 22%|██▏       | 104/467 [02:58<10:24,  1.72s/it]\u001b[A\n",
            " 22%|██▏       | 105/467 [03:00<10:21,  1.72s/it]\u001b[A\n",
            " 23%|██▎       | 106/467 [03:01<10:20,  1.72s/it]\u001b[A\n",
            " 23%|██▎       | 107/467 [03:03<10:14,  1.71s/it]\u001b[A\n",
            " 23%|██▎       | 108/467 [03:05<10:13,  1.71s/it]\u001b[A\n",
            " 23%|██▎       | 109/467 [03:06<10:11,  1.71s/it]\u001b[A\n",
            " 24%|██▎       | 110/467 [03:08<10:10,  1.71s/it]\u001b[A\n",
            " 24%|██▍       | 111/467 [03:10<10:07,  1.71s/it]\u001b[A\n",
            " 24%|██▍       | 112/467 [03:11<10:05,  1.70s/it]\u001b[A\n",
            " 24%|██▍       | 113/467 [03:13<10:05,  1.71s/it]\u001b[A\n",
            " 24%|██▍       | 114/467 [03:15<10:05,  1.71s/it]\u001b[A\n",
            " 25%|██▍       | 115/467 [03:17<10:05,  1.72s/it]\u001b[A\n",
            " 25%|██▍       | 116/467 [03:18<10:00,  1.71s/it]\u001b[A\n",
            " 25%|██▌       | 117/467 [03:20<09:56,  1.70s/it]\u001b[A\n",
            " 25%|██▌       | 118/467 [03:22<09:53,  1.70s/it]\u001b[A\n",
            " 25%|██▌       | 119/467 [03:23<09:50,  1.70s/it]\u001b[A\n",
            " 26%|██▌       | 120/467 [03:25<09:51,  1.70s/it]\u001b[A\n",
            " 26%|██▌       | 121/467 [03:27<09:51,  1.71s/it]\u001b[A\n",
            " 26%|██▌       | 122/467 [03:29<09:47,  1.70s/it]\u001b[A\n",
            " 26%|██▋       | 123/467 [03:30<09:45,  1.70s/it]\u001b[A\n",
            " 27%|██▋       | 124/467 [03:32<09:44,  1.70s/it]\u001b[A\n",
            " 27%|██▋       | 125/467 [03:34<09:39,  1.69s/it]\u001b[A\n",
            " 27%|██▋       | 126/467 [03:35<09:38,  1.70s/it]\u001b[A\n",
            " 27%|██▋       | 127/467 [03:37<09:39,  1.70s/it]\u001b[A\n",
            " 27%|██▋       | 128/467 [03:39<09:37,  1.70s/it]\u001b[A\n",
            " 28%|██▊       | 129/467 [03:40<09:35,  1.70s/it]\u001b[A\n",
            " 28%|██▊       | 130/467 [03:42<09:33,  1.70s/it]\u001b[A\n",
            " 28%|██▊       | 131/467 [03:44<09:33,  1.71s/it]\u001b[A\n",
            " 28%|██▊       | 132/467 [03:46<09:32,  1.71s/it]\u001b[A\n",
            " 28%|██▊       | 133/467 [03:47<09:32,  1.71s/it]\u001b[A\n",
            " 29%|██▊       | 134/467 [03:49<09:29,  1.71s/it]\u001b[A\n",
            " 29%|██▉       | 135/467 [03:51<09:27,  1.71s/it]\u001b[A\n",
            " 29%|██▉       | 136/467 [03:52<09:28,  1.72s/it]\u001b[A\n",
            " 29%|██▉       | 137/467 [03:54<09:28,  1.72s/it]\u001b[A\n",
            " 30%|██▉       | 138/467 [03:56<09:25,  1.72s/it]\u001b[A\n",
            " 30%|██▉       | 139/467 [03:58<09:21,  1.71s/it]\u001b[A\n",
            " 30%|██▉       | 140/467 [03:59<09:21,  1.72s/it]\u001b[A\n",
            " 30%|███       | 141/467 [04:01<09:18,  1.71s/it]\u001b[A\n",
            " 30%|███       | 142/467 [04:03<09:17,  1.72s/it]\u001b[A\n",
            " 31%|███       | 143/467 [04:04<09:15,  1.72s/it]\u001b[A\n",
            " 31%|███       | 144/467 [04:06<09:13,  1.71s/it]\u001b[A\n",
            " 31%|███       | 145/467 [04:08<09:13,  1.72s/it]\u001b[A\n",
            " 31%|███▏      | 146/467 [04:10<09:11,  1.72s/it]\u001b[A\n",
            " 31%|███▏      | 147/467 [04:11<09:08,  1.71s/it]\u001b[A\n",
            " 32%|███▏      | 148/467 [04:13<09:05,  1.71s/it]\u001b[A\n",
            " 32%|███▏      | 149/467 [04:15<09:03,  1.71s/it]\u001b[A\n",
            " 32%|███▏      | 150/467 [04:16<09:02,  1.71s/it]\u001b[A\n",
            " 32%|███▏      | 151/467 [04:18<09:02,  1.72s/it]\u001b[A\n",
            " 33%|███▎      | 152/467 [04:20<09:00,  1.72s/it]\u001b[A\n",
            " 33%|███▎      | 153/467 [04:22<08:56,  1.71s/it]\u001b[A\n",
            " 33%|███▎      | 154/467 [04:23<08:57,  1.72s/it]\u001b[A\n",
            " 33%|███▎      | 155/467 [04:25<08:55,  1.72s/it]\u001b[A\n",
            " 33%|███▎      | 156/467 [04:27<08:53,  1.72s/it]\u001b[A\n",
            " 34%|███▎      | 157/467 [04:28<08:51,  1.71s/it]\u001b[A\n",
            " 34%|███▍      | 158/467 [04:30<08:48,  1.71s/it]\u001b[A\n",
            " 34%|███▍      | 159/467 [04:32<08:46,  1.71s/it]\u001b[A\n",
            " 34%|███▍      | 160/467 [04:34<08:42,  1.70s/it]\u001b[A\n",
            " 34%|███▍      | 161/467 [04:35<08:42,  1.71s/it]\u001b[A\n",
            " 35%|███▍      | 162/467 [04:37<08:42,  1.71s/it]\u001b[A\n",
            " 35%|███▍      | 163/467 [04:39<08:40,  1.71s/it]\u001b[A\n",
            " 35%|███▌      | 164/467 [04:40<08:41,  1.72s/it]\u001b[A\n",
            " 35%|███▌      | 165/467 [04:42<08:41,  1.73s/it]\u001b[A\n",
            " 36%|███▌      | 166/467 [04:44<08:38,  1.72s/it]\u001b[A\n",
            " 36%|███▌      | 167/467 [04:46<08:35,  1.72s/it]\u001b[A\n",
            " 36%|███▌      | 168/467 [04:47<08:35,  1.72s/it]\u001b[A\n",
            " 36%|███▌      | 169/467 [04:49<08:31,  1.72s/it]\u001b[A\n",
            " 36%|███▋      | 170/467 [04:51<08:30,  1.72s/it]\u001b[A\n",
            " 37%|███▋      | 171/467 [04:53<08:27,  1.72s/it]\u001b[A\n",
            " 37%|███▋      | 172/467 [04:54<08:26,  1.72s/it]\u001b[A\n",
            " 37%|███▋      | 173/467 [04:56<08:24,  1.72s/it]\u001b[A\n",
            " 37%|███▋      | 174/467 [04:58<08:26,  1.73s/it]\u001b[A\n",
            " 37%|███▋      | 175/467 [04:59<08:24,  1.73s/it]\u001b[A\n",
            " 38%|███▊      | 176/467 [05:01<08:21,  1.72s/it]\u001b[A\n",
            " 38%|███▊      | 177/467 [05:03<08:18,  1.72s/it]\u001b[A\n",
            " 38%|███▊      | 178/467 [05:05<08:15,  1.72s/it]\u001b[A\n",
            " 38%|███▊      | 179/467 [05:06<08:12,  1.71s/it]\u001b[A\n",
            " 39%|███▊      | 180/467 [05:08<08:12,  1.71s/it]\u001b[A\n",
            " 39%|███▉      | 181/467 [05:10<08:11,  1.72s/it]\u001b[A\n",
            " 39%|███▉      | 182/467 [05:11<08:09,  1.72s/it]\u001b[A\n",
            " 39%|███▉      | 183/467 [05:13<08:10,  1.73s/it]\u001b[A\n",
            " 39%|███▉      | 184/467 [05:15<08:09,  1.73s/it]\u001b[A\n",
            " 40%|███▉      | 185/467 [05:17<08:06,  1.73s/it]\u001b[A\n",
            " 40%|███▉      | 186/467 [05:18<08:08,  1.74s/it]\u001b[A\n",
            " 40%|████      | 187/467 [05:20<08:04,  1.73s/it]\u001b[A\n",
            " 40%|████      | 188/467 [05:22<08:02,  1.73s/it]\u001b[A\n",
            " 40%|████      | 189/467 [05:24<08:00,  1.73s/it]\u001b[A\n",
            " 41%|████      | 190/467 [05:25<07:58,  1.73s/it]\u001b[A\n",
            " 41%|████      | 191/467 [05:27<07:54,  1.72s/it]\u001b[A\n",
            " 41%|████      | 192/467 [05:29<07:51,  1.71s/it]\u001b[A\n",
            " 41%|████▏     | 193/467 [05:30<07:51,  1.72s/it]\u001b[A\n",
            " 42%|████▏     | 194/467 [05:32<07:49,  1.72s/it]\u001b[A\n",
            " 42%|████▏     | 195/467 [05:34<07:48,  1.72s/it]\u001b[A\n",
            " 42%|████▏     | 196/467 [05:36<07:45,  1.72s/it]\u001b[A\n",
            " 42%|████▏     | 197/467 [05:37<07:43,  1.72s/it]\u001b[A\n",
            " 42%|████▏     | 198/467 [05:39<07:42,  1.72s/it]\u001b[A\n",
            " 43%|████▎     | 199/467 [05:41<07:38,  1.71s/it]\u001b[A\n",
            " 43%|████▎     | 200/467 [05:42<07:38,  1.72s/it]\u001b[A\n",
            " 43%|████▎     | 201/467 [05:44<07:38,  1.72s/it]\u001b[A\n",
            " 43%|████▎     | 202/467 [05:46<07:34,  1.71s/it]\u001b[A\n",
            " 43%|████▎     | 203/467 [05:48<07:33,  1.72s/it]\u001b[A\n",
            " 44%|████▎     | 204/467 [05:49<07:31,  1.72s/it]\u001b[A\n",
            " 44%|████▍     | 205/467 [05:51<07:28,  1.71s/it]\u001b[A\n",
            " 44%|████▍     | 206/467 [05:53<07:26,  1.71s/it]\u001b[A\n",
            " 44%|████▍     | 207/467 [05:54<07:25,  1.71s/it]\u001b[A\n",
            " 45%|████▍     | 208/467 [05:56<07:22,  1.71s/it]\u001b[A\n",
            " 45%|████▍     | 209/467 [05:58<07:22,  1.71s/it]\u001b[A\n",
            " 45%|████▍     | 210/467 [06:00<07:21,  1.72s/it]\u001b[A\n",
            " 45%|████▌     | 211/467 [06:01<07:19,  1.72s/it]\u001b[A\n",
            " 45%|████▌     | 212/467 [06:03<07:17,  1.71s/it]\u001b[A\n",
            " 46%|████▌     | 213/467 [06:05<07:15,  1.71s/it]\u001b[A\n",
            " 46%|████▌     | 214/467 [06:06<07:14,  1.72s/it]\u001b[A\n",
            " 46%|████▌     | 215/467 [06:08<07:14,  1.72s/it]\u001b[A\n",
            " 46%|████▋     | 216/467 [06:10<07:11,  1.72s/it]\u001b[A\n",
            " 46%|████▋     | 217/467 [06:12<07:06,  1.70s/it]\u001b[A\n",
            " 47%|████▋     | 218/467 [06:13<07:04,  1.70s/it]\u001b[A\n",
            " 47%|████▋     | 219/467 [06:15<07:03,  1.71s/it]\u001b[A\n",
            " 47%|████▋     | 220/467 [06:17<07:01,  1.70s/it]\u001b[A\n",
            " 47%|████▋     | 221/467 [06:18<07:00,  1.71s/it]\u001b[A\n",
            " 48%|████▊     | 222/467 [06:20<06:59,  1.71s/it]\u001b[A\n",
            " 48%|████▊     | 223/467 [06:22<06:58,  1.71s/it]\u001b[A\n",
            " 48%|████▊     | 224/467 [06:24<06:56,  1.71s/it]\u001b[A\n",
            " 48%|████▊     | 225/467 [06:25<06:54,  1.71s/it]\u001b[A\n",
            " 48%|████▊     | 226/467 [06:27<06:51,  1.71s/it]\u001b[A\n",
            " 49%|████▊     | 227/467 [06:29<06:48,  1.70s/it]\u001b[A\n",
            " 49%|████▉     | 228/467 [06:30<06:47,  1.71s/it]\u001b[A\n",
            " 49%|████▉     | 229/467 [06:32<06:45,  1.70s/it]\u001b[A\n",
            " 49%|████▉     | 230/467 [06:34<06:43,  1.70s/it]\u001b[A\n",
            " 49%|████▉     | 231/467 [06:35<06:42,  1.70s/it]\u001b[A\n",
            " 50%|████▉     | 232/467 [06:37<06:40,  1.70s/it]\u001b[A\n",
            " 50%|████▉     | 233/467 [06:39<06:41,  1.71s/it]\u001b[A\n",
            " 50%|█████     | 234/467 [06:41<06:39,  1.72s/it]\u001b[A\n",
            " 50%|█████     | 235/467 [06:42<06:37,  1.71s/it]\u001b[A\n",
            " 51%|█████     | 236/467 [06:44<06:34,  1.71s/it]\u001b[A\n",
            " 51%|█████     | 237/467 [06:46<06:33,  1.71s/it]\u001b[A\n",
            " 51%|█████     | 238/467 [06:47<06:32,  1.71s/it]\u001b[A\n",
            " 51%|█████     | 239/467 [06:49<06:30,  1.71s/it]\u001b[A\n",
            " 51%|█████▏    | 240/467 [06:51<06:28,  1.71s/it]\u001b[A\n",
            " 52%|█████▏    | 241/467 [06:53<06:28,  1.72s/it]\u001b[A\n",
            " 52%|█████▏    | 242/467 [06:54<06:26,  1.72s/it]\u001b[A\n",
            " 52%|█████▏    | 243/467 [06:56<06:24,  1.72s/it]\u001b[A\n",
            " 52%|█████▏    | 244/467 [06:58<06:22,  1.72s/it]\u001b[A\n",
            " 52%|█████▏    | 245/467 [06:59<06:22,  1.72s/it]\u001b[A\n",
            " 53%|█████▎    | 246/467 [07:01<06:17,  1.71s/it]\u001b[A\n",
            " 53%|█████▎    | 247/467 [07:03<06:15,  1.71s/it]\u001b[A\n",
            " 53%|█████▎    | 248/467 [07:05<06:15,  1.71s/it]\u001b[A\n",
            " 53%|█████▎    | 249/467 [07:06<06:13,  1.71s/it]\u001b[A\n",
            " 54%|█████▎    | 250/467 [07:08<06:14,  1.73s/it]\u001b[A\n",
            " 54%|█████▎    | 251/467 [07:10<06:13,  1.73s/it]\u001b[A\n",
            " 54%|█████▍    | 252/467 [07:12<06:09,  1.72s/it]\u001b[A\n",
            " 54%|█████▍    | 253/467 [07:13<06:07,  1.72s/it]\u001b[A\n",
            " 54%|█████▍    | 254/467 [07:15<06:03,  1.71s/it]\u001b[A\n",
            " 55%|█████▍    | 255/467 [07:17<06:01,  1.71s/it]\u001b[A\n",
            " 55%|█████▍    | 256/467 [07:18<06:01,  1.72s/it]\u001b[A\n",
            " 55%|█████▌    | 257/467 [07:20<06:00,  1.72s/it]\u001b[A\n",
            " 55%|█████▌    | 258/467 [07:22<05:57,  1.71s/it]\u001b[A\n",
            " 55%|█████▌    | 259/467 [07:23<05:57,  1.72s/it]\u001b[A\n",
            " 56%|█████▌    | 260/467 [07:25<05:55,  1.72s/it]\u001b[A\n",
            " 56%|█████▌    | 261/467 [07:27<05:54,  1.72s/it]\u001b[A\n",
            " 56%|█████▌    | 262/467 [07:29<05:51,  1.71s/it]\u001b[A\n",
            " 56%|█████▋    | 263/467 [07:30<05:49,  1.71s/it]\u001b[A\n",
            " 57%|█████▋    | 264/467 [07:32<05:47,  1.71s/it]\u001b[A\n",
            " 57%|█████▋    | 265/467 [07:34<05:44,  1.70s/it]\u001b[A\n",
            " 57%|█████▋    | 266/467 [07:35<05:41,  1.70s/it]\u001b[A\n",
            " 57%|█████▋    | 267/467 [07:37<05:39,  1.70s/it]\u001b[A\n",
            " 57%|█████▋    | 268/467 [07:39<05:37,  1.70s/it]\u001b[A\n",
            " 58%|█████▊    | 269/467 [07:40<05:34,  1.69s/it]\u001b[A\n",
            " 58%|█████▊    | 270/467 [07:42<05:33,  1.69s/it]\u001b[A\n",
            " 58%|█████▊    | 271/467 [07:44<05:30,  1.68s/it]\u001b[A\n",
            " 58%|█████▊    | 272/467 [07:46<05:29,  1.69s/it]\u001b[A\n",
            " 58%|█████▊    | 273/467 [07:47<05:27,  1.69s/it]\u001b[A\n",
            " 59%|█████▊    | 274/467 [07:49<05:44,  1.78s/it]\u001b[A\n",
            " 59%|█████▉    | 275/467 [07:51<05:37,  1.76s/it]\u001b[A\n",
            " 59%|█████▉    | 276/467 [07:53<05:31,  1.74s/it]\u001b[A\n",
            " 59%|█████▉    | 277/467 [07:54<05:27,  1.72s/it]\u001b[A\n",
            " 60%|█████▉    | 278/467 [07:56<05:23,  1.71s/it]\u001b[A\n",
            " 60%|█████▉    | 279/467 [07:58<05:19,  1.70s/it]\u001b[A\n",
            " 60%|█████▉    | 280/467 [07:59<05:17,  1.70s/it]\u001b[A\n",
            " 60%|██████    | 281/467 [08:01<05:15,  1.70s/it]\u001b[A\n",
            " 60%|██████    | 282/467 [08:03<05:13,  1.70s/it]\u001b[A\n",
            " 61%|██████    | 283/467 [08:04<05:11,  1.69s/it]\u001b[A\n",
            " 61%|██████    | 284/467 [08:06<05:08,  1.69s/it]\u001b[A\n",
            " 61%|██████    | 285/467 [08:08<05:06,  1.68s/it]\u001b[A\n",
            " 61%|██████    | 286/467 [08:10<05:05,  1.69s/it]\u001b[A\n",
            " 61%|██████▏   | 287/467 [08:11<05:04,  1.69s/it]\u001b[A\n",
            " 62%|██████▏   | 288/467 [08:13<05:02,  1.69s/it]\u001b[A\n",
            " 62%|██████▏   | 289/467 [08:15<05:00,  1.69s/it]\u001b[A\n",
            " 62%|██████▏   | 290/467 [08:16<04:58,  1.69s/it]\u001b[A\n",
            " 62%|██████▏   | 291/467 [08:18<04:56,  1.69s/it]\u001b[A\n",
            " 63%|██████▎   | 292/467 [08:20<04:55,  1.69s/it]\u001b[A\n",
            " 63%|██████▎   | 293/467 [08:21<04:53,  1.69s/it]\u001b[A\n",
            " 63%|██████▎   | 294/467 [08:23<04:53,  1.69s/it]\u001b[A\n",
            " 63%|██████▎   | 295/467 [08:25<04:50,  1.69s/it]\u001b[A\n",
            " 63%|██████▎   | 296/467 [08:26<04:49,  1.69s/it]\u001b[A\n",
            " 64%|██████▎   | 297/467 [08:28<04:47,  1.69s/it]\u001b[A\n",
            " 64%|██████▍   | 298/467 [08:30<04:45,  1.69s/it]\u001b[A\n",
            " 64%|██████▍   | 299/467 [08:31<04:42,  1.68s/it]\u001b[A\n",
            " 64%|██████▍   | 300/467 [08:33<04:41,  1.69s/it]\u001b[A\n",
            " 64%|██████▍   | 301/467 [08:35<04:39,  1.68s/it]\u001b[A\n",
            " 65%|██████▍   | 302/467 [08:36<04:37,  1.68s/it]\u001b[A\n",
            " 65%|██████▍   | 303/467 [08:38<04:36,  1.69s/it]\u001b[A\n",
            " 65%|██████▌   | 304/467 [08:40<04:34,  1.68s/it]\u001b[A\n",
            " 65%|██████▌   | 305/467 [08:42<04:32,  1.68s/it]\u001b[A\n",
            " 66%|██████▌   | 306/467 [08:43<04:31,  1.69s/it]\u001b[A\n",
            " 66%|██████▌   | 307/467 [08:45<04:30,  1.69s/it]\u001b[A\n",
            " 66%|██████▌   | 308/467 [08:47<04:28,  1.69s/it]\u001b[A\n",
            " 66%|██████▌   | 309/467 [08:48<04:27,  1.69s/it]\u001b[A\n",
            " 66%|██████▋   | 310/467 [08:50<04:25,  1.69s/it]\u001b[A\n",
            " 67%|██████▋   | 311/467 [08:52<04:23,  1.69s/it]\u001b[A\n",
            " 67%|██████▋   | 312/467 [08:53<04:20,  1.68s/it]\u001b[A\n",
            " 67%|██████▋   | 313/467 [08:55<04:19,  1.69s/it]\u001b[A\n",
            " 67%|██████▋   | 314/467 [08:57<04:17,  1.68s/it]\u001b[A\n",
            " 67%|██████▋   | 315/467 [08:58<04:15,  1.68s/it]\u001b[A\n",
            " 68%|██████▊   | 316/467 [09:00<04:14,  1.68s/it]\u001b[A\n",
            " 68%|██████▊   | 317/467 [09:02<04:12,  1.68s/it]\u001b[A\n",
            " 68%|██████▊   | 318/467 [09:03<04:10,  1.68s/it]\u001b[A\n",
            " 68%|██████▊   | 319/467 [09:05<04:09,  1.68s/it]\u001b[A\n",
            " 69%|██████▊   | 320/467 [09:07<04:07,  1.68s/it]\u001b[A\n",
            " 69%|██████▊   | 321/467 [09:09<04:06,  1.69s/it]\u001b[A\n",
            " 69%|██████▉   | 322/467 [09:10<04:05,  1.69s/it]\u001b[A\n",
            " 69%|██████▉   | 323/467 [09:12<04:03,  1.69s/it]\u001b[A\n",
            " 69%|██████▉   | 324/467 [09:14<04:01,  1.69s/it]\u001b[A\n",
            " 70%|██████▉   | 325/467 [09:15<04:00,  1.69s/it]\u001b[A\n",
            " 70%|██████▉   | 326/467 [09:17<03:58,  1.69s/it]\u001b[A\n",
            " 70%|███████   | 327/467 [09:19<03:56,  1.69s/it]\u001b[A\n",
            " 70%|███████   | 328/467 [09:20<03:54,  1.69s/it]\u001b[A\n",
            " 70%|███████   | 329/467 [09:22<03:52,  1.69s/it]\u001b[A\n",
            " 71%|███████   | 330/467 [09:24<03:50,  1.68s/it]\u001b[A\n",
            " 71%|███████   | 331/467 [09:25<03:48,  1.68s/it]\u001b[A\n",
            " 71%|███████   | 332/467 [09:27<03:46,  1.68s/it]\u001b[A\n",
            " 71%|███████▏  | 333/467 [09:29<03:45,  1.68s/it]\u001b[A\n",
            " 72%|███████▏  | 334/467 [09:30<03:43,  1.68s/it]\u001b[A\n",
            " 72%|███████▏  | 335/467 [09:32<03:42,  1.68s/it]\u001b[A\n",
            " 72%|███████▏  | 336/467 [09:34<03:40,  1.68s/it]\u001b[A\n",
            " 72%|███████▏  | 337/467 [09:35<03:38,  1.68s/it]\u001b[A\n",
            " 72%|███████▏  | 338/467 [09:37<03:37,  1.69s/it]\u001b[A\n",
            " 73%|███████▎  | 339/467 [09:39<03:36,  1.69s/it]\u001b[A\n",
            " 73%|███████▎  | 340/467 [09:41<03:35,  1.69s/it]\u001b[A\n",
            " 73%|███████▎  | 341/467 [09:42<03:34,  1.70s/it]\u001b[A\n",
            " 73%|███████▎  | 342/467 [09:44<03:31,  1.69s/it]\u001b[A\n",
            " 73%|███████▎  | 343/467 [09:46<03:30,  1.69s/it]\u001b[A\n",
            " 74%|███████▎  | 344/467 [09:47<03:29,  1.71s/it]\u001b[A\n",
            " 74%|███████▍  | 345/467 [09:49<03:27,  1.70s/it]\u001b[A\n",
            " 74%|███████▍  | 346/467 [09:51<03:25,  1.70s/it]\u001b[A\n",
            " 74%|███████▍  | 347/467 [09:52<03:24,  1.70s/it]\u001b[A\n",
            " 75%|███████▍  | 348/467 [09:54<03:22,  1.70s/it]\u001b[A\n",
            " 75%|███████▍  | 349/467 [09:56<03:20,  1.70s/it]\u001b[A\n",
            " 75%|███████▍  | 350/467 [09:58<03:18,  1.69s/it]\u001b[A\n",
            " 75%|███████▌  | 351/467 [09:59<03:16,  1.69s/it]\u001b[A\n",
            " 75%|███████▌  | 352/467 [10:01<03:14,  1.69s/it]\u001b[A\n",
            " 76%|███████▌  | 353/467 [10:03<03:13,  1.70s/it]\u001b[A\n",
            " 76%|███████▌  | 354/467 [10:04<03:11,  1.69s/it]\u001b[A\n",
            " 76%|███████▌  | 355/467 [10:06<03:10,  1.70s/it]\u001b[A\n",
            " 76%|███████▌  | 356/467 [10:08<03:08,  1.70s/it]\u001b[A\n",
            " 76%|███████▋  | 357/467 [10:09<03:07,  1.70s/it]\u001b[A\n",
            " 77%|███████▋  | 358/467 [10:11<03:05,  1.70s/it]\u001b[A\n",
            " 77%|███████▋  | 359/467 [10:13<03:04,  1.71s/it]\u001b[A\n",
            " 77%|███████▋  | 360/467 [10:15<03:03,  1.71s/it]\u001b[A\n",
            " 77%|███████▋  | 361/467 [10:16<03:01,  1.71s/it]\u001b[A\n",
            " 78%|███████▊  | 362/467 [10:18<02:59,  1.71s/it]\u001b[A\n",
            " 78%|███████▊  | 363/467 [10:20<02:56,  1.70s/it]\u001b[A\n",
            " 78%|███████▊  | 364/467 [10:21<02:54,  1.69s/it]\u001b[A\n",
            " 78%|███████▊  | 365/467 [10:23<02:52,  1.69s/it]\u001b[A\n",
            " 78%|███████▊  | 366/467 [10:25<02:50,  1.69s/it]\u001b[A\n",
            " 79%|███████▊  | 367/467 [10:26<02:49,  1.70s/it]\u001b[A\n",
            " 79%|███████▉  | 368/467 [10:28<02:47,  1.69s/it]\u001b[A\n",
            " 79%|███████▉  | 369/467 [10:30<02:45,  1.69s/it]\u001b[A\n",
            " 79%|███████▉  | 370/467 [10:32<02:44,  1.69s/it]\u001b[A\n",
            " 79%|███████▉  | 371/467 [10:33<02:42,  1.69s/it]\u001b[A\n",
            " 80%|███████▉  | 372/467 [10:35<02:40,  1.69s/it]\u001b[A\n",
            " 80%|███████▉  | 373/467 [10:37<02:39,  1.70s/it]\u001b[A\n",
            " 80%|████████  | 374/467 [10:38<02:38,  1.70s/it]\u001b[A\n",
            " 80%|████████  | 375/467 [10:40<02:36,  1.70s/it]\u001b[A\n",
            " 81%|████████  | 376/467 [10:42<02:34,  1.70s/it]\u001b[A\n",
            " 81%|████████  | 377/467 [10:43<02:32,  1.69s/it]\u001b[A\n",
            " 81%|████████  | 378/467 [10:45<02:30,  1.69s/it]\u001b[A\n",
            " 81%|████████  | 379/467 [10:47<02:28,  1.69s/it]\u001b[A\n",
            " 81%|████████▏ | 380/467 [10:48<02:26,  1.69s/it]\u001b[A\n",
            " 82%|████████▏ | 381/467 [10:50<02:24,  1.68s/it]\u001b[A\n",
            " 82%|████████▏ | 382/467 [10:52<02:22,  1.68s/it]\u001b[A\n",
            " 82%|████████▏ | 383/467 [10:53<02:21,  1.68s/it]\u001b[A\n",
            " 82%|████████▏ | 384/467 [10:55<02:20,  1.69s/it]\u001b[A\n",
            " 82%|████████▏ | 385/467 [10:57<02:18,  1.69s/it]\u001b[A\n",
            " 83%|████████▎ | 386/467 [10:59<02:16,  1.69s/it]\u001b[A\n",
            " 83%|████████▎ | 387/467 [11:00<02:14,  1.68s/it]\u001b[A\n",
            " 83%|████████▎ | 388/467 [11:02<02:13,  1.68s/it]\u001b[A\n",
            " 83%|████████▎ | 389/467 [11:04<02:11,  1.68s/it]\u001b[A\n",
            " 84%|████████▎ | 390/467 [11:05<02:10,  1.69s/it]\u001b[A\n",
            " 84%|████████▎ | 391/467 [11:07<02:08,  1.69s/it]\u001b[A\n",
            " 84%|████████▍ | 392/467 [11:09<02:07,  1.69s/it]\u001b[A\n",
            " 84%|████████▍ | 393/467 [11:10<02:05,  1.70s/it]\u001b[A\n",
            " 84%|████████▍ | 394/467 [11:12<02:04,  1.70s/it]\u001b[A\n",
            " 85%|████████▍ | 395/467 [11:14<02:02,  1.69s/it]\u001b[A\n",
            " 85%|████████▍ | 396/467 [11:16<02:01,  1.70s/it]\u001b[A\n",
            " 85%|████████▌ | 397/467 [11:17<01:59,  1.70s/it]\u001b[A\n",
            " 85%|████████▌ | 398/467 [11:19<01:57,  1.70s/it]\u001b[A\n",
            " 85%|████████▌ | 399/467 [11:21<01:55,  1.70s/it]\u001b[A\n",
            " 86%|████████▌ | 400/467 [11:22<01:53,  1.70s/it]\u001b[A\n",
            " 86%|████████▌ | 401/467 [11:24<01:51,  1.69s/it]\u001b[A\n",
            " 86%|████████▌ | 402/467 [11:26<01:49,  1.68s/it]\u001b[A\n",
            " 86%|████████▋ | 403/467 [11:27<01:47,  1.68s/it]\u001b[A\n",
            " 87%|████████▋ | 404/467 [11:29<01:46,  1.68s/it]\u001b[A\n",
            " 87%|████████▋ | 405/467 [11:31<01:44,  1.68s/it]\u001b[A\n",
            " 87%|████████▋ | 406/467 [11:32<01:42,  1.68s/it]\u001b[A\n",
            " 87%|████████▋ | 407/467 [11:34<01:40,  1.68s/it]\u001b[A\n",
            " 87%|████████▋ | 408/467 [11:36<01:39,  1.68s/it]\u001b[A\n",
            " 88%|████████▊ | 409/467 [11:37<01:37,  1.68s/it]\u001b[A\n",
            " 88%|████████▊ | 410/467 [11:39<01:35,  1.68s/it]\u001b[A\n",
            " 88%|████████▊ | 411/467 [11:41<01:34,  1.69s/it]\u001b[A\n",
            " 88%|████████▊ | 412/467 [11:42<01:32,  1.68s/it]\u001b[A\n",
            " 88%|████████▊ | 413/467 [11:44<01:30,  1.68s/it]\u001b[A\n",
            " 89%|████████▊ | 414/467 [11:46<01:29,  1.68s/it]\u001b[A\n",
            " 89%|████████▉ | 415/467 [11:48<01:27,  1.68s/it]\u001b[A\n",
            " 89%|████████▉ | 416/467 [11:49<01:25,  1.69s/it]\u001b[A\n",
            " 89%|████████▉ | 417/467 [11:51<01:24,  1.69s/it]\u001b[A\n",
            " 90%|████████▉ | 418/467 [11:53<01:22,  1.69s/it]\u001b[A\n",
            " 90%|████████▉ | 419/467 [11:54<01:21,  1.69s/it]\u001b[A\n",
            " 90%|████████▉ | 420/467 [11:56<01:19,  1.69s/it]\u001b[A\n",
            " 90%|█████████ | 421/467 [11:58<01:17,  1.69s/it]\u001b[A\n",
            " 90%|█████████ | 422/467 [11:59<01:15,  1.68s/it]\u001b[A\n",
            " 91%|█████████ | 423/467 [12:01<01:14,  1.68s/it]\u001b[A\n",
            " 91%|█████████ | 424/467 [12:03<01:12,  1.69s/it]\u001b[A\n",
            " 91%|█████████ | 425/467 [12:04<01:11,  1.70s/it]\u001b[A\n",
            " 91%|█████████ | 426/467 [12:06<01:09,  1.70s/it]\u001b[A\n",
            " 91%|█████████▏| 427/467 [12:08<01:08,  1.70s/it]\u001b[A\n",
            " 92%|█████████▏| 428/467 [12:10<01:06,  1.70s/it]\u001b[A\n",
            " 92%|█████████▏| 429/467 [12:11<01:04,  1.70s/it]\u001b[A\n",
            " 92%|█████████▏| 430/467 [12:13<01:03,  1.71s/it]\u001b[A\n",
            " 92%|█████████▏| 431/467 [12:15<01:01,  1.70s/it]\u001b[A\n",
            " 93%|█████████▎| 432/467 [12:16<00:59,  1.70s/it]\u001b[A\n",
            " 93%|█████████▎| 433/467 [12:18<00:57,  1.70s/it]\u001b[A\n",
            " 93%|█████████▎| 434/467 [12:20<00:55,  1.69s/it]\u001b[A\n",
            " 93%|█████████▎| 435/467 [12:21<00:54,  1.69s/it]\u001b[A\n",
            " 93%|█████████▎| 436/467 [12:23<00:52,  1.69s/it]\u001b[A\n",
            " 94%|█████████▎| 437/467 [12:25<00:50,  1.70s/it]\u001b[A\n",
            " 94%|█████████▍| 438/467 [12:27<00:49,  1.70s/it]\u001b[A\n",
            " 94%|█████████▍| 439/467 [12:28<00:47,  1.69s/it]\u001b[A\n",
            " 94%|█████████▍| 440/467 [12:30<00:45,  1.69s/it]\u001b[A\n",
            " 94%|█████████▍| 441/467 [12:32<00:43,  1.68s/it]\u001b[A\n",
            " 95%|█████████▍| 442/467 [12:33<00:41,  1.68s/it]\u001b[A\n",
            " 95%|█████████▍| 443/467 [12:35<00:40,  1.69s/it]\u001b[A\n",
            " 95%|█████████▌| 444/467 [12:37<00:38,  1.69s/it]\u001b[A\n",
            " 95%|█████████▌| 445/467 [12:38<00:37,  1.69s/it]\u001b[A\n",
            " 96%|█████████▌| 446/467 [12:40<00:35,  1.68s/it]\u001b[A\n",
            " 96%|█████████▌| 447/467 [12:42<00:33,  1.68s/it]\u001b[A\n",
            " 96%|█████████▌| 448/467 [12:43<00:31,  1.68s/it]\u001b[A\n",
            " 96%|█████████▌| 449/467 [12:45<00:30,  1.68s/it]\u001b[A\n",
            " 96%|█████████▋| 450/467 [12:47<00:28,  1.68s/it]\u001b[A\n",
            " 97%|█████████▋| 451/467 [12:48<00:26,  1.68s/it]\u001b[A\n",
            " 97%|█████████▋| 452/467 [12:50<00:25,  1.68s/it]\u001b[A\n",
            " 97%|█████████▋| 453/467 [12:52<00:23,  1.68s/it]\u001b[A\n",
            " 97%|█████████▋| 454/467 [12:53<00:21,  1.68s/it]\u001b[A\n",
            " 97%|█████████▋| 455/467 [12:55<00:20,  1.68s/it]\u001b[A\n",
            " 98%|█████████▊| 456/467 [12:57<00:18,  1.68s/it]\u001b[A\n",
            " 98%|█████████▊| 457/467 [12:58<00:16,  1.68s/it]\u001b[A\n",
            " 98%|█████████▊| 458/467 [13:00<00:15,  1.68s/it]\u001b[A\n",
            " 98%|█████████▊| 459/467 [13:02<00:13,  1.68s/it]\u001b[A\n",
            " 99%|█████████▊| 460/467 [13:03<00:11,  1.68s/it]\u001b[A\n",
            " 99%|█████████▊| 461/467 [13:05<00:10,  1.67s/it]\u001b[A\n",
            " 99%|█████████▉| 462/467 [13:07<00:08,  1.69s/it]\u001b[A\n",
            " 99%|█████████▉| 463/467 [13:09<00:06,  1.68s/it]\u001b[A\n",
            " 99%|█████████▉| 464/467 [13:10<00:05,  1.69s/it]\u001b[A\n",
            "100%|█████████▉| 465/467 [13:12<00:03,  1.69s/it]\u001b[A\n",
            "100%|█████████▉| 466/467 [13:14<00:01,  1.69s/it]\u001b[A\n",
            "100%|██████████| 467/467 [13:15<00:00,  1.70s/it]\n",
            "\n",
            "  0%|          | 0/117 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/117 [00:01<03:13,  1.67s/it]\u001b[A\n",
            "  2%|▏         | 2/117 [00:03<03:12,  1.67s/it]\u001b[A\n",
            "  3%|▎         | 3/117 [00:05<03:10,  1.67s/it]\u001b[A\n",
            "  3%|▎         | 4/117 [00:06<03:09,  1.67s/it]\u001b[A\n",
            "  4%|▍         | 5/117 [00:08<03:07,  1.68s/it]\u001b[A\n",
            "  5%|▌         | 6/117 [00:10<03:05,  1.67s/it]\u001b[A\n",
            "  6%|▌         | 7/117 [00:11<03:04,  1.68s/it]\u001b[A\n",
            "  7%|▋         | 8/117 [00:13<03:02,  1.67s/it]\u001b[A\n",
            "  8%|▊         | 9/117 [00:15<03:01,  1.68s/it]\u001b[A\n",
            "  9%|▊         | 10/117 [00:16<02:59,  1.68s/it]\u001b[A\n",
            "  9%|▉         | 11/117 [00:18<02:58,  1.68s/it]\u001b[A\n",
            " 10%|█         | 12/117 [00:20<02:56,  1.69s/it]\u001b[A\n",
            " 11%|█         | 13/117 [00:21<02:54,  1.68s/it]\u001b[A\n",
            " 12%|█▏        | 14/117 [00:23<02:54,  1.69s/it]\u001b[A\n",
            " 13%|█▎        | 15/117 [00:25<02:52,  1.69s/it]\u001b[A\n",
            " 14%|█▎        | 16/117 [00:26<02:51,  1.70s/it]\u001b[A\n",
            " 15%|█▍        | 17/117 [00:28<02:48,  1.69s/it]\u001b[A\n",
            " 15%|█▌        | 18/117 [00:30<02:46,  1.68s/it]\u001b[A\n",
            " 16%|█▌        | 19/117 [00:31<02:45,  1.69s/it]\u001b[A\n",
            " 17%|█▋        | 20/117 [00:33<02:42,  1.68s/it]\u001b[A\n",
            " 18%|█▊        | 21/117 [00:35<02:40,  1.68s/it]\u001b[A\n",
            " 19%|█▉        | 22/117 [00:36<02:39,  1.68s/it]\u001b[A\n",
            " 20%|█▉        | 23/117 [00:38<02:37,  1.68s/it]\u001b[A\n",
            " 21%|██        | 24/117 [00:40<02:36,  1.68s/it]\u001b[A\n",
            " 21%|██▏       | 25/117 [00:42<02:34,  1.68s/it]\u001b[A\n",
            " 22%|██▏       | 26/117 [00:43<02:32,  1.68s/it]\u001b[A\n",
            " 23%|██▎       | 27/117 [00:45<02:30,  1.68s/it]\u001b[A\n",
            " 24%|██▍       | 28/117 [00:47<02:29,  1.68s/it]\u001b[A\n",
            " 25%|██▍       | 29/117 [00:48<02:27,  1.67s/it]\u001b[A\n",
            " 26%|██▌       | 30/117 [00:50<02:26,  1.68s/it]\u001b[A\n",
            " 26%|██▋       | 31/117 [00:52<02:24,  1.68s/it]\u001b[A\n",
            " 27%|██▋       | 32/117 [00:53<02:23,  1.69s/it]\u001b[A\n",
            " 28%|██▊       | 33/117 [00:55<02:21,  1.69s/it]\u001b[A\n",
            " 29%|██▉       | 34/117 [00:57<02:20,  1.69s/it]\u001b[A\n",
            " 30%|██▉       | 35/117 [00:58<02:18,  1.69s/it]\u001b[A\n",
            " 31%|███       | 36/117 [01:00<02:17,  1.70s/it]\u001b[A\n",
            " 32%|███▏      | 37/117 [01:02<02:16,  1.70s/it]\u001b[A\n",
            " 32%|███▏      | 38/117 [01:03<02:14,  1.70s/it]\u001b[A\n",
            " 33%|███▎      | 39/117 [01:05<02:12,  1.69s/it]\u001b[A\n",
            " 34%|███▍      | 40/117 [01:07<02:09,  1.69s/it]\u001b[A\n",
            " 35%|███▌      | 41/117 [01:09<02:08,  1.69s/it]\u001b[A\n",
            " 36%|███▌      | 42/117 [01:10<02:07,  1.70s/it]\u001b[A\n",
            " 37%|███▋      | 43/117 [01:12<02:06,  1.70s/it]\u001b[A\n",
            " 38%|███▊      | 44/117 [01:14<02:04,  1.70s/it]\u001b[A\n",
            " 38%|███▊      | 45/117 [01:15<02:01,  1.69s/it]\u001b[A\n",
            " 39%|███▉      | 46/117 [01:17<02:00,  1.69s/it]\u001b[A\n",
            " 40%|████      | 47/117 [01:19<01:58,  1.69s/it]\u001b[A\n",
            " 41%|████      | 48/117 [01:20<01:56,  1.69s/it]\u001b[A\n",
            " 42%|████▏     | 49/117 [01:22<01:55,  1.69s/it]\u001b[A\n",
            " 43%|████▎     | 50/117 [01:24<01:53,  1.70s/it]\u001b[A\n",
            " 44%|████▎     | 51/117 [01:25<01:51,  1.69s/it]\u001b[A\n",
            " 44%|████▍     | 52/117 [01:27<01:50,  1.69s/it]\u001b[A\n",
            " 45%|████▌     | 53/117 [01:29<01:48,  1.69s/it]\u001b[A\n",
            " 46%|████▌     | 54/117 [01:31<01:46,  1.69s/it]\u001b[A\n",
            " 47%|████▋     | 55/117 [01:32<01:44,  1.69s/it]\u001b[A\n",
            " 48%|████▊     | 56/117 [01:34<01:43,  1.69s/it]\u001b[A\n",
            " 49%|████▊     | 57/117 [01:36<01:40,  1.68s/it]\u001b[A\n",
            " 50%|████▉     | 58/117 [01:37<01:39,  1.69s/it]\u001b[A\n",
            " 50%|█████     | 59/117 [01:39<01:38,  1.69s/it]\u001b[A\n",
            " 51%|█████▏    | 60/117 [01:41<01:36,  1.69s/it]\u001b[A\n",
            " 52%|█████▏    | 61/117 [01:42<01:34,  1.69s/it]\u001b[A\n",
            " 53%|█████▎    | 62/117 [01:44<01:33,  1.69s/it]\u001b[A\n",
            " 54%|█████▍    | 63/117 [01:46<01:31,  1.69s/it]\u001b[A\n",
            " 55%|█████▍    | 64/117 [01:47<01:29,  1.69s/it]\u001b[A\n",
            " 56%|█████▌    | 65/117 [01:49<01:27,  1.69s/it]\u001b[A\n",
            " 56%|█████▋    | 66/117 [01:51<01:25,  1.69s/it]\u001b[A\n",
            " 57%|█████▋    | 67/117 [01:53<01:24,  1.69s/it]\u001b[A\n",
            " 58%|█████▊    | 68/117 [01:54<01:22,  1.69s/it]\u001b[A\n",
            " 59%|█████▉    | 69/117 [01:56<01:21,  1.69s/it]\u001b[A\n",
            " 60%|█████▉    | 70/117 [01:58<01:19,  1.69s/it]\u001b[A\n",
            " 61%|██████    | 71/117 [01:59<01:17,  1.69s/it]\u001b[A\n",
            " 62%|██████▏   | 72/117 [02:01<01:15,  1.68s/it]\u001b[A\n",
            " 62%|██████▏   | 73/117 [02:03<01:14,  1.69s/it]\u001b[A\n",
            " 63%|██████▎   | 74/117 [02:04<01:12,  1.69s/it]\u001b[A\n",
            " 64%|██████▍   | 75/117 [02:06<01:10,  1.69s/it]\u001b[A\n",
            " 65%|██████▍   | 76/117 [02:08<01:09,  1.69s/it]\u001b[A\n",
            " 66%|██████▌   | 77/117 [02:09<01:07,  1.69s/it]\u001b[A\n",
            " 67%|██████▋   | 78/117 [02:11<01:05,  1.69s/it]\u001b[A\n",
            " 68%|██████▊   | 79/117 [02:13<01:04,  1.69s/it]\u001b[A\n",
            " 68%|██████▊   | 80/117 [02:14<01:02,  1.69s/it]\u001b[A\n",
            " 69%|██████▉   | 81/117 [02:16<01:00,  1.68s/it]\u001b[A\n",
            " 70%|███████   | 82/117 [02:18<00:59,  1.69s/it]\u001b[A\n",
            " 71%|███████   | 83/117 [02:20<00:57,  1.69s/it]\u001b[A\n",
            " 72%|███████▏  | 84/117 [02:21<00:55,  1.69s/it]\u001b[A\n",
            " 73%|███████▎  | 85/117 [02:23<00:54,  1.69s/it]\u001b[A\n",
            " 74%|███████▎  | 86/117 [02:25<00:52,  1.69s/it]\u001b[A\n",
            " 74%|███████▍  | 87/117 [02:26<00:50,  1.70s/it]\u001b[A\n",
            " 75%|███████▌  | 88/117 [02:28<00:49,  1.70s/it]\u001b[A\n",
            " 76%|███████▌  | 89/117 [02:30<00:47,  1.70s/it]\u001b[A\n",
            " 77%|███████▋  | 90/117 [02:31<00:45,  1.69s/it]\u001b[A\n",
            " 78%|███████▊  | 91/117 [02:33<00:45,  1.74s/it]\u001b[A\n",
            " 79%|███████▊  | 92/117 [02:35<00:45,  1.83s/it]\u001b[A\n",
            " 79%|███████▉  | 93/117 [02:37<00:42,  1.79s/it]\u001b[A\n",
            " 80%|████████  | 94/117 [02:39<00:40,  1.76s/it]\u001b[A\n",
            " 81%|████████  | 95/117 [02:40<00:38,  1.74s/it]\u001b[A\n",
            " 82%|████████▏ | 96/117 [02:42<00:36,  1.72s/it]\u001b[A\n",
            " 83%|████████▎ | 97/117 [02:44<00:34,  1.71s/it]\u001b[A\n",
            " 84%|████████▍ | 98/117 [02:45<00:32,  1.71s/it]\u001b[A\n",
            " 85%|████████▍ | 99/117 [02:47<00:30,  1.70s/it]\u001b[A\n",
            " 85%|████████▌ | 100/117 [02:49<00:28,  1.70s/it]\u001b[A\n",
            " 86%|████████▋ | 101/117 [02:51<00:27,  1.70s/it]\u001b[A\n",
            " 87%|████████▋ | 102/117 [02:52<00:25,  1.70s/it]\u001b[A\n",
            " 88%|████████▊ | 103/117 [02:54<00:23,  1.70s/it]\u001b[A\n",
            " 89%|████████▉ | 104/117 [02:56<00:22,  1.70s/it]\u001b[A\n",
            " 90%|████████▉ | 105/117 [02:57<00:20,  1.70s/it]\u001b[A\n",
            " 91%|█████████ | 106/117 [02:59<00:18,  1.70s/it]\u001b[A\n",
            " 91%|█████████▏| 107/117 [03:01<00:16,  1.70s/it]\u001b[A\n",
            " 92%|█████████▏| 108/117 [03:02<00:15,  1.70s/it]\u001b[A\n",
            " 93%|█████████▎| 109/117 [03:04<00:13,  1.70s/it]\u001b[A\n",
            " 94%|█████████▍| 110/117 [03:06<00:11,  1.70s/it]\u001b[A\n",
            " 95%|█████████▍| 111/117 [03:08<00:10,  1.70s/it]\u001b[A\n",
            " 96%|█████████▌| 112/117 [03:09<00:08,  1.70s/it]\u001b[A\n",
            " 97%|█████████▋| 113/117 [03:11<00:06,  1.70s/it]\u001b[A\n",
            " 97%|█████████▋| 114/117 [03:13<00:05,  1.69s/it]\u001b[A\n",
            " 98%|█████████▊| 115/117 [03:14<00:03,  1.69s/it]\u001b[A\n",
            " 99%|█████████▉| 116/117 [03:16<00:01,  1.69s/it]\u001b[A\n",
            "100%|██████████| 117/117 [03:18<00:00,  1.69s/it]\n",
            "\n",
            "  0%|          | 0/174 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/174 [00:01<04:58,  1.72s/it]\u001b[A\n",
            "  1%|          | 2/174 [00:03<04:54,  1.71s/it]\u001b[A\n",
            "  2%|▏         | 3/174 [00:05<04:52,  1.71s/it]\u001b[A\n",
            "  2%|▏         | 4/174 [00:06<04:49,  1.70s/it]\u001b[A\n",
            "  3%|▎         | 5/174 [00:08<04:46,  1.70s/it]\u001b[A\n",
            "  3%|▎         | 6/174 [00:10<04:45,  1.70s/it]\u001b[A\n",
            "  4%|▍         | 7/174 [00:11<04:44,  1.70s/it]\u001b[A\n",
            "  5%|▍         | 8/174 [00:13<04:43,  1.71s/it]\u001b[A\n",
            "  5%|▌         | 9/174 [00:15<04:41,  1.71s/it]\u001b[A\n",
            "  6%|▌         | 10/174 [00:17<04:39,  1.70s/it]\u001b[A\n",
            "  6%|▋         | 11/174 [00:18<04:37,  1.70s/it]\u001b[A\n",
            "  7%|▋         | 12/174 [00:20<04:36,  1.71s/it]\u001b[A\n",
            "  7%|▋         | 13/174 [00:22<04:33,  1.70s/it]\u001b[A\n",
            "  8%|▊         | 14/174 [00:23<04:32,  1.70s/it]\u001b[A\n",
            "  9%|▊         | 15/174 [00:25<04:30,  1.70s/it]\u001b[A\n",
            "  9%|▉         | 16/174 [00:27<04:27,  1.69s/it]\u001b[A\n",
            " 10%|▉         | 17/174 [00:28<04:24,  1.69s/it]\u001b[A\n",
            " 10%|█         | 18/174 [00:30<04:22,  1.68s/it]\u001b[A\n",
            " 11%|█         | 19/174 [00:32<04:21,  1.68s/it]\u001b[A\n",
            " 11%|█▏        | 20/174 [00:33<04:19,  1.68s/it]\u001b[A\n",
            " 12%|█▏        | 21/174 [00:35<04:18,  1.69s/it]\u001b[A\n",
            " 13%|█▎        | 22/174 [00:37<04:15,  1.68s/it]\u001b[A\n",
            " 13%|█▎        | 23/174 [00:38<04:14,  1.68s/it]\u001b[A\n",
            " 14%|█▍        | 24/174 [00:40<04:12,  1.69s/it]\u001b[A\n",
            " 14%|█▍        | 25/174 [00:42<04:11,  1.68s/it]\u001b[A\n",
            " 15%|█▍        | 26/174 [00:44<04:09,  1.69s/it]\u001b[A\n",
            " 16%|█▌        | 27/174 [00:45<04:08,  1.69s/it]\u001b[A\n",
            " 16%|█▌        | 28/174 [00:47<04:05,  1.68s/it]\u001b[A\n",
            " 17%|█▋        | 29/174 [00:49<04:04,  1.69s/it]\u001b[A\n",
            " 17%|█▋        | 30/174 [00:50<04:03,  1.69s/it]\u001b[A\n",
            " 18%|█▊        | 31/174 [00:52<04:02,  1.69s/it]\u001b[A\n",
            " 18%|█▊        | 32/174 [00:54<03:59,  1.68s/it]\u001b[A\n",
            " 19%|█▉        | 33/174 [00:55<03:57,  1.68s/it]\u001b[A\n",
            " 20%|█▉        | 34/174 [00:57<03:56,  1.69s/it]\u001b[A\n",
            " 20%|██        | 35/174 [00:59<03:54,  1.68s/it]\u001b[A\n",
            " 21%|██        | 36/174 [01:00<03:52,  1.68s/it]\u001b[A\n",
            " 21%|██▏       | 37/174 [01:02<03:50,  1.68s/it]\u001b[A\n",
            " 22%|██▏       | 38/174 [01:04<03:49,  1.69s/it]\u001b[A\n",
            " 22%|██▏       | 39/174 [01:05<03:47,  1.69s/it]\u001b[A\n",
            " 23%|██▎       | 40/174 [01:07<03:46,  1.69s/it]\u001b[A\n",
            " 24%|██▎       | 41/174 [01:09<03:43,  1.68s/it]\u001b[A\n",
            " 24%|██▍       | 42/174 [01:11<03:43,  1.69s/it]\u001b[A\n",
            " 25%|██▍       | 43/174 [01:12<03:41,  1.69s/it]\u001b[A\n",
            " 25%|██▌       | 44/174 [01:14<03:40,  1.70s/it]\u001b[A\n",
            " 26%|██▌       | 45/174 [01:16<03:39,  1.70s/it]\u001b[A\n",
            " 26%|██▋       | 46/174 [01:17<03:38,  1.71s/it]\u001b[A\n",
            " 27%|██▋       | 47/174 [01:19<03:36,  1.71s/it]\u001b[A\n",
            " 28%|██▊       | 48/174 [01:21<03:34,  1.70s/it]\u001b[A\n",
            " 28%|██▊       | 49/174 [01:22<03:32,  1.70s/it]\u001b[A\n",
            " 29%|██▊       | 50/174 [01:24<03:30,  1.70s/it]\u001b[A\n",
            " 29%|██▉       | 51/174 [01:26<03:28,  1.70s/it]\u001b[A\n",
            " 30%|██▉       | 52/174 [01:28<03:26,  1.69s/it]\u001b[A\n",
            " 30%|███       | 53/174 [01:29<03:25,  1.70s/it]\u001b[A\n",
            " 31%|███       | 54/174 [01:31<03:23,  1.70s/it]\u001b[A\n",
            " 32%|███▏      | 55/174 [01:33<03:22,  1.70s/it]\u001b[A\n",
            " 32%|███▏      | 56/174 [01:34<03:21,  1.71s/it]\u001b[A\n",
            " 33%|███▎      | 57/174 [01:36<03:18,  1.70s/it]\u001b[A\n",
            " 33%|███▎      | 58/174 [01:38<03:16,  1.70s/it]\u001b[A\n",
            " 34%|███▍      | 59/174 [01:39<03:14,  1.69s/it]\u001b[A\n",
            " 34%|███▍      | 60/174 [01:41<03:13,  1.69s/it]\u001b[A\n",
            " 35%|███▌      | 61/174 [01:43<03:10,  1.69s/it]\u001b[A\n",
            " 36%|███▌      | 62/174 [01:44<03:09,  1.69s/it]\u001b[A\n",
            " 36%|███▌      | 63/174 [01:46<03:08,  1.70s/it]\u001b[A\n",
            " 37%|███▋      | 64/174 [01:48<03:05,  1.69s/it]\u001b[A\n",
            " 37%|███▋      | 65/174 [01:50<03:04,  1.69s/it]\u001b[A\n",
            " 38%|███▊      | 66/174 [01:51<03:02,  1.69s/it]\u001b[A\n",
            " 39%|███▊      | 67/174 [01:53<03:01,  1.69s/it]\u001b[A\n",
            " 39%|███▉      | 68/174 [01:55<03:00,  1.70s/it]\u001b[A\n",
            " 40%|███▉      | 69/174 [01:56<02:58,  1.70s/it]\u001b[A\n",
            " 40%|████      | 70/174 [01:58<02:57,  1.70s/it]\u001b[A\n",
            " 41%|████      | 71/174 [02:00<02:54,  1.70s/it]\u001b[A\n",
            " 41%|████▏     | 72/174 [02:01<02:53,  1.70s/it]\u001b[A\n",
            " 42%|████▏     | 73/174 [02:03<02:51,  1.70s/it]\u001b[A\n",
            " 43%|████▎     | 74/174 [02:05<02:50,  1.70s/it]\u001b[A\n",
            " 43%|████▎     | 75/174 [02:07<02:48,  1.70s/it]\u001b[A\n",
            " 44%|████▎     | 76/174 [02:08<02:46,  1.70s/it]\u001b[A\n",
            " 44%|████▍     | 77/174 [02:10<02:44,  1.70s/it]\u001b[A\n",
            " 45%|████▍     | 78/174 [02:12<02:42,  1.69s/it]\u001b[A\n",
            " 45%|████▌     | 79/174 [02:13<02:40,  1.69s/it]\u001b[A\n",
            " 46%|████▌     | 80/174 [02:15<02:38,  1.69s/it]\u001b[A\n",
            " 47%|████▋     | 81/174 [02:17<02:36,  1.68s/it]\u001b[A\n",
            " 47%|████▋     | 82/174 [02:18<02:34,  1.68s/it]\u001b[A\n",
            " 48%|████▊     | 83/174 [02:20<02:32,  1.68s/it]\u001b[A\n",
            " 48%|████▊     | 84/174 [02:22<02:31,  1.69s/it]\u001b[A\n",
            " 49%|████▉     | 85/174 [02:23<02:29,  1.68s/it]\u001b[A\n",
            " 49%|████▉     | 86/174 [02:25<02:28,  1.69s/it]\u001b[A\n",
            " 50%|█████     | 87/174 [02:27<02:26,  1.69s/it]\u001b[A\n",
            " 51%|█████     | 88/174 [02:29<02:25,  1.69s/it]\u001b[A\n",
            " 51%|█████     | 89/174 [02:30<02:24,  1.70s/it]\u001b[A\n",
            " 52%|█████▏    | 90/174 [02:32<02:22,  1.69s/it]\u001b[A\n",
            " 52%|█████▏    | 91/174 [02:34<02:21,  1.70s/it]\u001b[A\n",
            " 53%|█████▎    | 92/174 [02:35<02:19,  1.71s/it]\u001b[A\n",
            " 53%|█████▎    | 93/174 [02:37<02:17,  1.70s/it]\u001b[A\n",
            " 54%|█████▍    | 94/174 [02:39<02:15,  1.70s/it]\u001b[A\n",
            " 55%|█████▍    | 95/174 [02:40<02:14,  1.70s/it]\u001b[A\n",
            " 55%|█████▌    | 96/174 [02:42<02:12,  1.70s/it]\u001b[A\n",
            " 56%|█████▌    | 97/174 [02:44<02:10,  1.70s/it]\u001b[A\n",
            " 56%|█████▋    | 98/174 [02:45<02:08,  1.69s/it]\u001b[A\n",
            " 57%|█████▋    | 99/174 [02:47<02:06,  1.69s/it]\u001b[A\n",
            " 57%|█████▋    | 100/174 [02:49<02:05,  1.70s/it]\u001b[A\n",
            " 58%|█████▊    | 101/174 [02:51<02:04,  1.70s/it]\u001b[A\n",
            " 59%|█████▊    | 102/174 [02:52<02:02,  1.70s/it]\u001b[A\n",
            " 59%|█████▉    | 103/174 [02:54<01:59,  1.69s/it]\u001b[A\n",
            " 60%|█████▉    | 104/174 [02:56<01:58,  1.69s/it]\u001b[A\n",
            " 60%|██████    | 105/174 [02:57<01:56,  1.69s/it]\u001b[A\n",
            " 61%|██████    | 106/174 [02:59<01:54,  1.68s/it]\u001b[A\n",
            " 61%|██████▏   | 107/174 [03:01<01:52,  1.68s/it]\u001b[A\n",
            " 62%|██████▏   | 108/174 [03:02<01:50,  1.68s/it]\u001b[A\n",
            " 63%|██████▎   | 109/174 [03:04<01:49,  1.68s/it]\u001b[A\n",
            " 63%|██████▎   | 110/174 [03:06<01:47,  1.68s/it]\u001b[A\n",
            " 64%|██████▍   | 111/174 [03:07<01:45,  1.68s/it]\u001b[A\n",
            " 64%|██████▍   | 112/174 [03:09<01:44,  1.68s/it]\u001b[A\n",
            " 65%|██████▍   | 113/174 [03:11<01:42,  1.69s/it]\u001b[A\n",
            " 66%|██████▌   | 114/174 [03:12<01:41,  1.69s/it]\u001b[A\n",
            " 66%|██████▌   | 115/174 [03:14<01:39,  1.68s/it]\u001b[A\n",
            " 67%|██████▋   | 116/174 [03:16<01:37,  1.69s/it]\u001b[A\n",
            " 67%|██████▋   | 117/174 [03:18<01:36,  1.69s/it]\u001b[A\n",
            " 68%|██████▊   | 118/174 [03:19<01:34,  1.69s/it]\u001b[A\n",
            " 68%|██████▊   | 119/174 [03:21<01:32,  1.69s/it]\u001b[A\n",
            " 69%|██████▉   | 120/174 [03:23<01:31,  1.69s/it]\u001b[A\n",
            " 70%|██████▉   | 121/174 [03:24<01:29,  1.69s/it]\u001b[A\n",
            " 70%|███████   | 122/174 [03:26<01:27,  1.69s/it]\u001b[A\n",
            " 71%|███████   | 123/174 [03:28<01:25,  1.69s/it]\u001b[A\n",
            " 71%|███████▏  | 124/174 [03:29<01:24,  1.68s/it]\u001b[A\n",
            " 72%|███████▏  | 125/174 [03:31<01:22,  1.69s/it]\u001b[A\n",
            " 72%|███████▏  | 126/174 [03:33<01:20,  1.68s/it]\u001b[A\n",
            " 73%|███████▎  | 127/174 [03:34<01:19,  1.68s/it]\u001b[A\n",
            " 74%|███████▎  | 128/174 [03:36<01:17,  1.68s/it]\u001b[A\n",
            " 74%|███████▍  | 129/174 [03:38<01:15,  1.68s/it]\u001b[A\n",
            " 75%|███████▍  | 130/174 [03:39<01:14,  1.69s/it]\u001b[A\n",
            " 75%|███████▌  | 131/174 [03:41<01:12,  1.69s/it]\u001b[A\n",
            " 76%|███████▌  | 132/174 [03:43<01:10,  1.68s/it]\u001b[A\n",
            " 76%|███████▋  | 133/174 [03:45<01:09,  1.68s/it]\u001b[A\n",
            " 77%|███████▋  | 134/174 [03:46<01:07,  1.69s/it]\u001b[A\n",
            " 78%|███████▊  | 135/174 [03:48<01:05,  1.68s/it]\u001b[A\n",
            " 78%|███████▊  | 136/174 [03:50<01:03,  1.68s/it]\u001b[A\n",
            " 79%|███████▊  | 137/174 [03:51<01:02,  1.68s/it]\u001b[A\n",
            " 79%|███████▉  | 138/174 [03:53<01:00,  1.68s/it]\u001b[A\n",
            " 80%|███████▉  | 139/174 [03:55<00:58,  1.68s/it]\u001b[A\n",
            " 80%|████████  | 140/174 [03:56<00:57,  1.69s/it]\u001b[A\n",
            " 81%|████████  | 141/174 [03:58<00:55,  1.69s/it]\u001b[A\n",
            " 82%|████████▏ | 142/174 [04:00<00:53,  1.69s/it]\u001b[A\n",
            " 82%|████████▏ | 143/174 [04:01<00:52,  1.69s/it]\u001b[A\n",
            " 83%|████████▎ | 144/174 [04:03<00:50,  1.69s/it]\u001b[A\n",
            " 83%|████████▎ | 145/174 [04:05<00:49,  1.69s/it]\u001b[A\n",
            " 84%|████████▍ | 146/174 [04:06<00:47,  1.70s/it]\u001b[A\n",
            " 84%|████████▍ | 147/174 [04:08<00:45,  1.69s/it]\u001b[A\n",
            " 85%|████████▌ | 148/174 [04:10<00:43,  1.68s/it]\u001b[A\n",
            " 86%|████████▌ | 149/174 [04:11<00:42,  1.69s/it]\u001b[A\n",
            " 86%|████████▌ | 150/174 [04:13<00:40,  1.69s/it]\u001b[A\n",
            " 87%|████████▋ | 151/174 [04:15<00:38,  1.69s/it]\u001b[A\n",
            " 87%|████████▋ | 152/174 [04:17<00:37,  1.69s/it]\u001b[A\n",
            " 88%|████████▊ | 153/174 [04:18<00:35,  1.70s/it]\u001b[A\n",
            " 89%|████████▊ | 154/174 [04:20<00:33,  1.69s/it]\u001b[A\n",
            " 89%|████████▉ | 155/174 [04:22<00:32,  1.69s/it]\u001b[A\n",
            " 90%|████████▉ | 156/174 [04:23<00:30,  1.69s/it]\u001b[A\n",
            " 90%|█████████ | 157/174 [04:25<00:28,  1.69s/it]\u001b[A\n",
            " 91%|█████████ | 158/174 [04:27<00:27,  1.69s/it]\u001b[A\n",
            " 91%|█████████▏| 159/174 [04:28<00:25,  1.69s/it]\u001b[A\n",
            " 92%|█████████▏| 160/174 [04:30<00:23,  1.69s/it]\u001b[A\n",
            " 93%|█████████▎| 161/174 [04:32<00:22,  1.69s/it]\u001b[A\n",
            " 93%|█████████▎| 162/174 [04:34<00:20,  1.70s/it]\u001b[A\n",
            " 94%|█████████▎| 163/174 [04:35<00:18,  1.70s/it]\u001b[A\n",
            " 94%|█████████▍| 164/174 [04:37<00:17,  1.70s/it]\u001b[A\n",
            " 95%|█████████▍| 165/174 [04:39<00:15,  1.71s/it]\u001b[A\n",
            " 95%|█████████▌| 166/174 [04:40<00:13,  1.70s/it]\u001b[A\n",
            " 96%|█████████▌| 167/174 [04:42<00:11,  1.70s/it]\u001b[A\n",
            " 97%|█████████▋| 168/174 [04:44<00:10,  1.70s/it]\u001b[A\n",
            " 97%|█████████▋| 169/174 [04:45<00:08,  1.70s/it]\u001b[A\n",
            " 98%|█████████▊| 170/174 [04:47<00:06,  1.70s/it]\u001b[A\n",
            " 98%|█████████▊| 171/174 [04:49<00:05,  1.70s/it]\u001b[A\n",
            " 99%|█████████▉| 172/174 [04:51<00:03,  1.71s/it]\u001b[A\n",
            " 99%|█████████▉| 173/174 [04:52<00:01,  1.70s/it]\u001b[A\n",
            "100%|██████████| 174/174 [04:54<00:00,  1.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train F1 score: 0.9907407407407408\n",
            "Validation F1 score: 0.9444444444444444\n",
            "Test F1 score: 0.8413793103448277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbkByyq0edss"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}